
import torch.nn as nn
import logging
import numpy as np
from sklearn.metrics.pairwise import cosine_similarity
import os
from datetime import datetime
import time
import torch.nn.functional as F
logger = logging.getLogger(__name__)
import torch
import torch.distributed as dist
import torch.multiprocessing as mp
from dataset import RecordDataset, RelationBuilder,FullDataset
from configs.dataset_config import *
import json
import pandas as pd
from EndToEndContrastiveModel import EndToEndContrastiveModel


class Generator(nn.Module):
    def __init__(self, input_dim=658, out_dim=329, max_adjust=0.2):
        super().__init__()
        '''
        self.net = nn.Sequential(
            nn.Linear(input_dim, 512),
            #nn.LayerNorm(512),          # ğŸ‘ˆ åŠ åœ¨è¿™é‡Œ
            #nn.Linear(512, 512),
            #nn.ReLU(0.2),
            #nn.Dropout(0.5),  # æ–°å¢ï¼šè¾“å…¥å±‚åç«‹å³Dropout
            nn.Linear(512,out_dim),
            nn.LeakyReLU(0.2),
            #nn.Linear(128, out_dim),
            #nn.LeakyReLU(0.2),
            nn.Dropout(0.2),
            nn.Tanh()  # è¾“å‡ºèŒƒå›´æ˜¯ [-1, 1]
        )
        
        #self.max_adjust = nn.Parameter(torch.tensor(0.2))  # ä¼šè‡ªåŠ¨ä¼˜åŒ–
        self.max_adjust = 0.5 # ä¼šè‡ªåŠ¨ä¼˜åŒ–
        '''
        self.net = nn.Sequential(
            nn.Linear(input_dim, 256),  # å‡å°‘å‚æ•°é‡
            nn.LayerNorm(256),          # æ¢å¤ LayerNorm
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),            # å¢å¼º Dropout
            nn.Linear(256, out_dim),
            #nn.Tanh()
        )
        self.max_adjust = 1.0
        self._init_weights()
    def _init_weights(self):
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)   # Xavier ä¿æŒè¾“å…¥è¾“å‡ºæ–¹å·®ç¨³å®š
                if m.bias is not None:
                    nn.init.zeros_(m.bias)
            elif isinstance(m, nn.LayerNorm):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)

    def forward(self, stu_emb,difficulty_input):
        x = torch.cat([stu_emb,difficulty_input], dim=1)
        adjustment = self.net(x) * self.max_adjust  # å…è®¸è°ƒèŠ‚å¹…åº¦
       
        return adjustment

import time
import torch  
from concurrent.futures import ThreadPoolExecutor
import gc
import os
import torch
import numpy as np
from concurrent.futures import ThreadPoolExecutor
class LambdaLayer(nn.Module):
    def __init__(self, func):
        super(LambdaLayer, self).__init__()
        self.func = func

    def forward(self, x):
        return self.func(x)



import torch
import torch.nn as nn
import torch.nn.functional as F

class KnowledgeDifficulty(nn.Module):
    """
    è¾“å…¥: X (B, N, L)
    è¾“å‡º: difficulty (B, M) 0~1
    æ¯ä¸ªçŸ¥è¯†æ¦‚å¿µç‹¬ç«‹å…³æ³¨é¢˜ç›®çš„Nä¸ªè§’åº¦
    ä»…é’ˆå¯¹æ¶‰åŠçš„çŸ¥è¯†æ¦‚å¿µå­¦ä¹ æƒé‡
    """
    def __init__(self, L, M):
        super(KnowledgeDifficulty, self).__init__()
        self.L = L      # æ¯ä¸ªè§’åº¦çš„ç‰¹å¾ç»´åº¦
        self.M = M      # çŸ¥è¯†æ¦‚å¿µæ•°é‡

        # å­¦ä¹ æ¯ä¸ªçŸ¥è¯†æ¦‚å¿µå¯¹æ¯ä¸ªè§’åº¦çš„æƒé‡
        self.angle_attn = nn.Linear(L, M)  # L -> M

        # å°†åŠ æƒåçš„ç‰¹å¾æ˜ å°„æˆæ ‡é‡éš¾åº¦
        self.to_scalar = nn.Linear(L, 1)
                # åˆå§‹åŒ–å‚æ•°
        self._init_weights()

    def _init_weights(self):
        # angle_attn: Xavier åˆå§‹åŒ–æ›´åˆé€‚
        nn.init.xavier_uniform_(self.angle_attn.weight)
        nn.init.constant_(self.angle_attn.bias, 0.)

        # to_scalar: Kaiming ä¹Ÿå¯ä»¥ï¼Œä½†è¿™é‡Œè¾“å‡ºå¾ˆå°ï¼Œç”¨ Xavier æ›´ç¨³
        nn.init.xavier_uniform_(self.to_scalar.weight)
        nn.init.constant_(self.to_scalar.bias, 0.)

    def forward(self, X, K=None):
        """
        X: (B, N, L)
        K: (B, M) 0/1, çŸ¥è¯†æ¦‚å¿µæ©ç ï¼Œè¡¨ç¤ºé¢˜ç›®æ¶‰åŠçš„çŸ¥è¯†æ¦‚å¿µ
        """
        B, N, L = X.shape

        if K is None:
            # å¦‚æœæ²¡æœ‰æä¾›æ©ç ï¼Œå°±å¯¹æ‰€æœ‰çŸ¥è¯†æ¦‚å¿µè®¡ç®—
            weights = self.angle_attn(X)       # (B, N, M)
            weights = torch.softmax(weights, dim=1)
            X_exp = X.unsqueeze(2)             # (B, N, 1, L)
            weights_exp = weights.unsqueeze(-1) # (B, N, M, 1)
            X_weighted = (X_exp * weights_exp).sum(dim=1)  # (B, M, L)
            difficulty = self.to_scalar(X_weighted).squeeze(-1)
            difficulty = torch.sigmoid(difficulty)
            return difficulty

        # ä»…é€‰æ‹©æ¶‰åŠçš„çŸ¥è¯†æ¦‚å¿µ
        involved_idx = [torch.nonzero(K[b], as_tuple=False).squeeze(-1) for b in range(B)]

        difficulties = []
        for b in range(B):
            if len(involved_idx[b]) == 0:
                # å¦‚æœæ²¡æœ‰æ¶‰åŠçŸ¥è¯†æ¦‚å¿µ
                difficulties.append(torch.zeros(K.shape[1], device=X.device))
                continue
            # å–å‡ºæ¶‰åŠçš„çŸ¥è¯†æ¦‚å¿µç´¢å¼•
            idx = involved_idx[b]
            # è®¡ç®—è¿™äº›çŸ¥è¯†æ¦‚å¿µçš„æƒé‡
            weights_b = self.angle_attn(X[b])[:, idx]  # (N, num_involved)
            weights_b = torch.softmax(weights_b, dim=0)  # å¯¹Nä¸ªè§’åº¦å½’ä¸€åŒ–

            X_exp = X[b].unsqueeze(1)                  # (N, 1, L)
            weights_exp = weights_b.unsqueeze(-1)      # (N, num_involved, 1)
            X_weighted = (X_exp * weights_exp).sum(dim=0)  # (num_involved, L)

            diff_b = torch.sigmoid(self.to_scalar(X_weighted).squeeze(-1))  # (num_involved,)

            # æ”¾å›åˆ°åŸæ¥çš„ M å¤§å°
            full_diff = torch.zeros(K.shape[1], device=X.device)
            full_diff[idx] = diff_b.to(full_diff.dtype)
            difficulties.append(full_diff)

        # åˆå¹¶ batch
        difficulty = torch.stack(difficulties, dim=0)  # (B, M)
        return difficulty
class SNRDifficultyHead(nn.Module):
    def __init__(self, feature_dim=256):
        super().__init__()
        self.feature_dim = feature_dim
        
        # 1. ç®€å•çš„èšç„¦å±‚ (Focus): æŠŠ 196 ç»´å˜æˆ 1 ç»´
        # æˆ‘ä»¬ç”¨çŸ¥è¯†ç‚¹å»"åŠ æƒ"å›¾ç‰‡ï¼Œè€Œä¸æ˜¯ç”Ÿç¡¬çš„ MaxPool
        self.attn_fc = nn.Linear(feature_dim, 1) 

        # 2. éš¾åº¦é¢„æµ‹å™¨ (MLP)
        # è¾“å…¥ç»´åº¦æ˜¯ 2: [ç›¸å…³å¼ºåº¦(æŠ•å½±é•¿), å¹²æ‰°å¼ºåº¦(å™ªå£°é•¿)]
        # æˆ–è€…æˆ‘ä»¬å¯ä»¥è¾“å…¥æ›´å¤šå‡ ä½•ç‰¹å¾ï¼Œè¿™é‡Œä¿æŒæç®€
        self.predictor = nn.Sequential(
            nn.Linear(2, 64),
            nn.ReLU(),
            nn.Linear(64, 32),
            nn.ReLU(),
            nn.Linear(32, 1)
        )

    def forward(self, img_feat, know_feat):
        """
        img_feat:  [N, 196, 256] (N = Batché‡Œè¿™å°±é“é¢˜æ¶‰åŠçš„çŸ¥è¯†ç‚¹æ€»æ•°)
        know_feat: [N, 256]
        """
        
        # --- A. èšç„¦ (Focus) ---
        # æ—¢ç„¶è¦åšå‘é‡å‡æ³•ï¼Œæˆ‘ä»¬éœ€è¦å…ˆæŠŠ 196 ä¸ªå—åˆæˆä¸€ä¸ª"ä»£è¡¨å‘é‡"
        # è¿™é‡Œç”¨ä¸€ç§æç®€çš„ Softmax Attention
        # é€»è¾‘ï¼šè·ŸçŸ¥è¯†ç‚¹è¶Šåƒçš„å—ï¼Œæƒé‡è¶Šå¤§
        
        # [N, 196, 256] * [N, 1, 256] -> Sum(-1) -> [N, 196]
        scores = torch.sum(img_feat * know_feat.unsqueeze(1), dim=-1) 
        weights = F.softmax(scores, dim=1).unsqueeze(-1) # [N, 196, 1]
        
        # åŠ æƒæ±‚å’Œ: [N, 196, 256] * [N, 196, 1] -> Sum(1) -> [N, 256]
        focused_img = torch.sum(img_feat * weights, dim=1)
        
        # --- B. å‡ ä½•åˆ†è§£ (Geometric Decomposition) ---
        
        # 1. å½’ä¸€åŒ– (å…³é”®ï¼å‡ ä½•æŠ•å½±å¿…é¡»åœ¨å•ä½çƒé¢ä¸Šåš)
        I_norm = F.normalize(focused_img, p=2, dim=-1)
        K_norm = F.normalize(know_feat, p=2, dim=-1)
        
        # 2. è®¡ç®—æŠ•å½± (æœ‰æ•ˆä¿¡æ¯ / Signal)
        # Dot Product: è¿™é“é¢˜é‡Œæœ‰å¤šå°‘æˆåˆ†æ˜¯å±äºè¿™ä¸ªçŸ¥è¯†ç‚¹çš„ï¼Ÿ
        # [N, 1]
        relevance_scalar = torch.sum(I_norm * K_norm, dim=-1, keepdim=True)
        relevance_vec = relevance_scalar * K_norm
        
        # 3. è®¡ç®—æ­£äº¤å™ªå£° (å¹²æ‰°ä¿¡æ¯ / Noise)
        # åŸå§‹å‘é‡ - æœ‰æ•ˆå‘é‡ = å‰©ä¸‹çš„æ²¡ç”¨/å¹²æ‰°å‘é‡
        noise_vec = I_norm - relevance_vec
        
        # è®¡ç®—å™ªå£°çš„æ¨¡é•¿ (Magnitude)
        noise_scalar = torch.norm(noise_vec, p=2, dim=-1, keepdim=True)
        
        # --- C. é¢„æµ‹éš¾åº¦ ---
        # æ‹¼æ¥ [æœ‰æ•ˆæ€§, å¹²æ‰°æ€§] -> [N, 2]
        # ç¥ç»ç½‘ç»œä¼šå­¦ä¼šï¼šæœ‰æ•ˆæ€§ä½ + å¹²æ‰°æ€§é«˜ = éš¾
        geometric_features = torch.cat([relevance_scalar, noise_scalar], dim=-1)
        
        difficulty = torch.sigmoid(self.predictor(geometric_features))
        
        return difficulty
from torch.utils.checkpoint import checkpoint
class Net(nn.Module):
    def __init__(self, student_n, exer_n, knowledge_n, problem_dataset):
        """
        åˆå§‹åŒ–ç½‘ç»œç»“æ„å’Œå‚æ•°ã€‚
        :param student_n: int, å­¦ç”Ÿæ•°é‡
        :param exer_n: int, ç»ƒä¹ é¢˜æ•°é‡
        :param knowledge_n: int, çŸ¥è¯†ç‚¹æ•°é‡
        :param problem_features: torch.Tensor, é¢˜ç›®ç‰¹å¾ (shape: [exer_n, 512])
        :param knowledge_features: torch.Tensor, çŸ¥è¯†ç‰¹å¾ (shape: [knowledge_n, 512])
        :param exer_kn_graph: torch.Tensor, é¢˜ç›®-çŸ¥è¯†ç‚¹å…³è”çŸ©é˜µ (shape: [exer_n, knowledge_n])
        """
        super(Net, self).__init__()
        
       
        self.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

        self.generator = Generator(input_dim=knowledge_n+1024,out_dim=knowledge_n) 
        

        
        # å‚æ•°åˆå§‹åŒ–
        self.knowledge_dim = knowledge_n
        self.exer_n = exer_n
        self.emb_num = student_n
        self.stu_dim = self.knowledge_dim
        self.prednet_input_len = self.knowledge_dim
        self.prednet_len1, self.prednet_len2 = 512, 256
        
        # å­¦ç”ŸåµŒå…¥å±‚
        self.student_emb = nn.Embedding(self.emb_num, self.stu_dim)
                # ç»ƒä¹ é¢˜çš„çŸ¥è¯†ç‚¹éš¾åº¦åµŒå…¥ï¼Œshape = [ç»ƒä¹ æ•°é‡, çŸ¥è¯†ç‚¹ç»´åº¦]
        self.k_difficulty = nn.Embedding(self.exer_n, self.knowledge_dim)
        self.exer_feat = nn.Embedding(self.exer_n, 2)
        self.student_emb_text = nn.Embedding(self.emb_num, self.stu_dim)
        self.student_emb_img = nn.Embedding(self.emb_num, self.stu_dim)
        # ç¡®ä¿æ‰€æœ‰ç»„ä»¶åœ¨ç»Ÿä¸€è®¾å¤‡
      


        
        # ç»ƒä¹ é¢˜çš„åŒºåˆ†åº¦åµŒå…¥ï¼Œshape = [ç»ƒä¹ æ•°é‡, 1]
        #self.e_discrimination = nn.Embedding(self.exer_n, 1)
        # é¢„æµ‹ç½‘ç»œ
        self.prednet_full1 = nn.Linear(self.prednet_input_len, self.prednet_len1)
        self.drop_1 = nn.Dropout(p=0.5)
        self.prednet_full2 = nn.Linear(self.prednet_len1, self.prednet_len2)
        self.drop_2 = nn.Dropout(p=0.5)
        self.prednet_full3 = nn.Linear(self.prednet_len2, 1)
        
        self.pre = nn.Linear(self.knowledge_dim,1)
        self.problem_dataset = problem_dataset
      
        # ä¿®æ”¹ï¼šGCNè¾“å‡ºä½œä¸ºä¿®æ­£é‡ï¼Œè€Œéç›´æ¥æ›¿æ¢

        self.full_dataset = FullDataset()

        # æ„å»ºå¼‚è´¨å›¾
        self.relation_builder = RelationBuilder(self.problem_dataset, self.full_dataset)
        self.hetero_graph = self.relation_builder.build_graph()


        
        self.alpha = nn.Parameter(torch.tensor(0.3))  # è°ƒæ•´èåˆç³»æ•°èŒƒå›´
        
        #self.problem_feat = self.hetero_graph['problem'].x.float().to(self.device)
        #self.knowledge_feat = self.hetero_graph['knowledge'].x.float().to(self.device)

        print("\nç‰¹å¾ç»´åº¦éªŒè¯:")
        #print(f"é¢˜ç›®ç‰¹å¾çŸ©é˜µ shape: {self.problem_feat.shape} | dtype: {self.problem_feat.dtype} ")
        #print(f"çŸ¥è¯†ç‚¹ç‰¹å¾çŸ©é˜µ shape: {self.knowledge_feat.shape} | dtype: {self.knowledge_feat.dtype} ")
        '''
        # ä¿®æ”¹åçš„ difficulty_net å’Œ e_discrimination
        self.difficulty_net = nn.Sequential(
            nn.Linear(1024, 256),
            nn.LayerNorm(256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),
            nn.Linear(256, knowledge_n),
            nn.Sigmoid()
        )

        self.e_discrimination = nn.Sequential(
            nn.Linear(1024, 256),
            nn.LayerNorm(256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),
            nn.Linear(256, knowledge_n*2),
            nn.Unflatten(1, (2, knowledge_n)),  # æ‹†åˆ†ä¸º scale å’Œ bias
            
            # æ ¸å¿ƒåŒºåˆ†åº¦è®¡ç®—
            LambdaLayer(lambda x: ((x[:,0] * 2.5).tanh() * x[:,1].sigmoid()) * 5 + 5)
        )
        '''

        # å…±äº«åº•å±‚ç‰¹å¾æå–
        self.shared_encoder = nn.Sequential(
            nn.Linear(1024, 512),
            nn.LayerNorm(512),
            nn.LeakyReLU(0.2)
        )
        '''
        # éš¾åº¦ä¸“å±åˆ†æ”¯
        self.diff_head = nn.Sequential(
            nn.Linear(1024, 512),
            nn.LayerNorm(512),              # åŠ  LayerNorm
            nn.ReLU(),  
            nn.Linear(512, 256),
            nn.LayerNorm(256),              # åŠ  LayerNorm
            nn.ReLU(),                      # æˆ– LeakyReLU()
            nn.Dropout(0.3),
            nn.Linear(256, knowledge_n),
            nn.Sigmoid()
        )
                # åŒºåˆ†åº¦ä¸“å±åˆ†æ”¯
        self.disc_head = nn.Sequential(
            nn.Linear(1024, 512),
            nn.LayerNorm(512),              # åŠ  LayerNorm
            nn.ReLU(),  
            nn.Linear(512, 256),
            nn.LayerNorm(256),              # åŠ  LayerNorm
            nn.ReLU(),                      # æˆ– LeakyReLU()
            nn.Dropout(0.3),
            nn.Linear(256, knowledge_n),
            nn.Sigmoid()
        )
        '''
        '''
                # éš¾åº¦ä¸“å±åˆ†æ”¯
        self.diff_head = nn.Sequential(
            nn.Linear(1024, 256),
            nn.LayerNorm(256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),
            nn.Linear(256, knowledge_n),
            nn.Sigmoid()
        )
                # åŒºåˆ†åº¦ä¸“å±åˆ†æ”¯
        self.disc_head = nn.Sequential(
            nn.Linear(1024, 256),
            nn.LayerNorm(256),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),
            nn.Linear(256, knowledge_n),
            nn.Sigmoid()
        )
        '''

                # éš¾åº¦ä¸“å±åˆ†æ”¯
        self.diff_head = nn.Sequential(
            nn.Linear(2048, 512),
            nn.LayerNorm(512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),
            nn.Linear(512, knowledge_n),
            nn.Sigmoid()
        )
                # åŒºåˆ†åº¦ä¸“å±åˆ†æ”¯
        self.disc_head = nn.Sequential(
            nn.Linear(2048, 512),
            nn.LayerNorm(512),
            nn.LeakyReLU(0.2),
            nn.Dropout(0.4),
            nn.Linear(512, knowledge_n*2),
            nn.Unflatten(1, (2, knowledge_n)),  # æ‹†åˆ†ä¸º scale å’Œ bias
            
            # æ ¸å¿ƒåŒºåˆ†åº¦è®¡ç®—
            LambdaLayer(lambda x: ((x[:,0] * 2.5).tanh() * x[:,1].sigmoid()) * 5 + 5)
        )

        '''
        # åŒºåˆ†åº¦ä¸“å±åˆ†æ”¯
        self.disc_head = nn.Sequential(
            nn.Linear(1024, 256),
            nn.LayerNorm(256),
            nn.ReLU(), 
            nn.LeakyReLU(0.2),
            nn.Linear(256, knowledge_n),
            nn.Sigmoid()
        )
        '''
        
        self.diff_M = KnowledgeDifficulty(L=80, M=knowledge_n)
        
        self.disc_M = KnowledgeDifficulty(L=80, M=knowledge_n)
        
      
       
        self.to(self.device)

         ###åŠ¨æ€æ›´æ–°ç‰¹å¾èåˆ
        self.model_feat = EndToEndContrastiveModel().to(self.device)
        
        self.t = 300
        self.sum = 0
        
        
        self.problem_mapper = nn.Sequential(
            nn.Linear(1024, 512),
            nn.ReLU(),
           
        )
        self.knowledge_mapper = torch.nn.Linear(1024, 512)

        self.kc_importance = nn.Parameter(torch.full((1, self.knowledge_dim), 0.5))

        self.kc_importance_layer = nn.Sequential(
            nn.Linear(1024, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 1)
        )

        #self.student_freq_tensor, self.user_ids = self.get_student_freq_tensor(KNOWLEDGE_FREQ_CSV)
        #self.student_weights = self.get_student_weights(STUDENT_WEIGHT,student_n)
        #self.student_freq_tensor = self.student_freq_tensor.to(self.device)
        #self.student_weights = self.student_weights.to(self.device)
        self.q = 1

        self.beta = nn.Parameter(torch.tensor(0.5), requires_grad=True)

        # ç„¶åèµ‹å€¼
        self.problem_768 = nn.Linear(768,512)
        # å¯å­¦ä¹ çš„æ”¾å¤§å‚æ•°
        self.freq_amplifier = nn.Parameter(torch.tensor(10.0))  # åˆå§‹æ”¾å¤§å€æ•°
        self.base_scale = nn.Parameter(torch.tensor(6.0))       # åŸºç¡€åŒºåˆ†åº¦åŸºæ•°
        self.freq_power = nn.Parameter(torch.tensor(0.5))       # éçº¿æ€§å˜æ¢æŒ‡æ•°
        
    # éš¾åº¦é¢„æµ‹ä¸“ç”¨çš„å±‚
        self.diff_item_proj = nn.Linear(1024, 512)  # é¢˜ç›®ç‰¹å¾æŠ•å½±
        self.diff_knowledge_emb = nn.Embedding(knowledge_n, 512)  # çŸ¥è¯†ç‚¹åµŒå…¥
        self.diff_scale = nn.Parameter(torch.tensor(1.0))  # ç¼©æ”¾å‚æ•°
        self.diff_bias = nn.Parameter(torch.tensor(0.0))   # åç½®å‚æ•°
        
        self.disc_item_proj = nn.Linear(1024, 512)  # é¢˜ç›®ç‰¹å¾æŠ•å½±
        self.disc_knowledge_emb = nn.Embedding(knowledge_n, 512)  # çŸ¥è¯†ç‚¹åµŒå…¥
        self.disc_scale = nn.Parameter(torch.tensor(1.0))  # ç¼©æ”¾å‚æ•°
        self.disc_bias = nn.Parameter(torch.tensor(0.0))   # åç½®å‚æ•°
        
        
        self.problem = nn.Embedding(self.exer_n, 1024)

        self.problem_text = nn.Embedding(self.exer_n, 512)
        self.problem_img = nn.Embedding(self.exer_n, 512)



         # æ­£ç¡®å®šä¹‰ç»´åº¦
        self.C = 512   # è¯­ä¹‰é€šé“æ•°
        self.M = 50    # æ± åŒ–åç»´åº¦
        
        # ç‰¹å¾é€‚é…å™¨
        self.feature_adapter = nn.Sequential(
            nn.Conv1d(512, self.C, kernel_size=1),  # ä»768ç»´åˆ°512ä¸ªé€šé“
            nn.AdaptiveMaxPool1d(self.M)  # æ± åŒ–åˆ°å›ºå®šç»´åº¦50
        )
        
        
        
       
        
        #self.problem_features = self.load_all_features(TEXT_FEATURES_DIR)



        self.output_layer = nn.Linear(knowledge_n, 1)
        self.feature_weights = nn.Parameter(torch.randn(329))  # è‡ªå®šä¹‰329ä¸ªæƒé‡
        '''
        csv_file = '/mnt/proj/autodl-tmp/data_2/XES3G5M/concept_frequency_percentage.csv'
        df = pd.read_csv(csv_file)

        self.vector_329 = np.zeros(329)  # å…ˆåˆ›å»ºå…¨0å‘é‡
        for _, row in df.iterrows():
            cid = int(row['concept_id'])
            if 0 <= cid < 329:
                self.vector_329[cid] = row['percentage']

        # ç°åœ¨ vector_329 å°±æ˜¯é•¿åº¦ä¸º 329 çš„ä¸€ç»´å‘é‡
        # vector_329[0] å¯¹åº” concept_id = 0
        # vector_329[100] å¯¹åº” concept_id = 100ï¼Œä¾æ­¤ç±»æ¨

        print("å‘é‡é•¿åº¦:", len(self.vector_329))
        print("ç¬¬0ä¸ªçŸ¥è¯†ç‚¹ç™¾åˆ†æ¯”:", self.vector_329[0])

        '''
        # ç»Ÿä¸€ç‰¹å¾ç»´åº¦
        self.FEATURE_DIM = 256 # 768
        self.GATE_HIDDEN_DIM = 128     # é—¨æ§ç½‘ç»œçš„éšè—å±‚ç»´åº¦
        self.DIFF_HIDDEN_DIM = 128     # éš¾åº¦å¤´éšè—å±‚ç»´åº¦
        self.LATENT_K_DIM = 256         # W_p æŠ•å½±çš„çŸ¥è¯†ç‚¹æ½œåœ¨ç»´åº¦ (ä½ åŸå…ˆçš„40)

        # ----------------------------------------------------------------------
        # NCDM åŸºç¡€å±‚ (768ç»´ç‰¹å¾çš„èåˆèµ·ç‚¹)
        # ----------------------------------------------------------------------
        self.student_emb = nn.Embedding(student_n, self.knowledge_dim)
        self.k_difficulty_NCDM = nn.Embedding(self.exer_n, self.knowledge_dim)
        self.e_discrimination_NCDM = nn.Embedding(self.exer_n, 1)

        # ----------------------------------------------------------------------
        # Fusion æ ¸å¿ƒå±‚ (éœ€é€‚åº” 768 ç»´)
        # ----------------------------------------------------------------------
        
        # W_på‚æ•°ï¼šå¿…é¡»ä»ç‰¹å¾ç»´åº¦ (768) æŠ•å½±åˆ°ä½ çš„æ½œåœ¨ç»´åº¦ (40)
        self.W_p = nn.Parameter(torch.randn(self.FEATURE_DIM, self.LATENT_K_DIM) * 0.02)
        
        # éš¾åº¦å¤´ (è¾“å…¥æ˜¯ Attention èšåˆåçš„ 768 ç»´å‘é‡)
        self.fusion_dropout = nn.Dropout(p=0.5) 
        self.diff_head_k = nn.Sequential(
            nn.Linear(self.FEATURE_DIM, self.DIFF_HIDDEN_DIM), # âœ… 768 -> 384
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(self.DIFF_HIDDEN_DIM, 1)
        )
        self.norm = nn.LayerNorm(self.FEATURE_DIM * 2)
        # ----------------------------------------------------------------------
        # ä¸ªæ€§åŒ– GateNet (è¾“å…¥ä¸º Mean+Max: 1536 ç»´)
        # ----------------------------------------------------------------------
        self.gate_net = nn.Sequential(
            nn.Linear(self.FEATURE_DIM * 2, self.GATE_HIDDEN_DIM), # âœ… 1536 -> 128
            nn.ReLU(),
            nn.Linear(self.GATE_HIDDEN_DIM, 1)
        )
        # --- å…³é”®ä¿®æ”¹åœ¨è¿™é‡Œ ---
        
        
        # æœ€ç»ˆè¾“å‡ºå±‚
        self.output_layer = nn.Linear(knowledge_n, 1)


        print(f"âš¡ [Model] æ­£åœ¨å°†ç¦»çº¿ç‰¹å¾åŠ è½½åˆ° GPU æ˜¾å­˜: {OUTPUT_FILE} ...")
        cache = torch.load(OUTPUT_FILE, map_location='cpu') # å…ˆè¯»åˆ° CPU
        
        # å‡è®¾é¢˜ç›®IDæ˜¯è¿ç»­çš„ 0 ~ 947ã€‚å¦‚æœä¸è¿ç»­ï¼Œéœ€è¦ä½ è‡ªå·±åšæ˜ å°„è¡¨ã€‚
        # æˆ‘ä»¬æŒ‰ PID æ’åºï¼Œç¡®ä¿ç´¢å¼•å¯¹é½
        sorted_pids = sorted(list(cache.keys()))
        
        # --- 1. å¤„ç†å›¾åƒç‰¹å¾ (4å±‚) ---
        # ç»“æ„: cache[pid]['img'] æ˜¯ä¸€ä¸ª list [L1, L2, L3, L4]
        # æˆ‘ä»¬è¦æŠŠæ‰€æœ‰é¢˜ç›®çš„ L1 æ‹¼åœ¨ä¸€èµ· -> [948, C, H, W]
        print("   æ­£åœ¨å †å å›¾åƒç‰¹å¾...")
        self.register_buffer('bank_img_l1', torch.stack([cache[p]['img'][0] for p in sorted_pids]))
        self.register_buffer('bank_img_l2', torch.stack([cache[p]['img'][1] for p in sorted_pids]))
        self.register_buffer('bank_img_l3', torch.stack([cache[p]['img'][2] for p in sorted_pids]))
        self.register_buffer('bank_img_l4', torch.stack([cache[p]['img'][3] for p in sorted_pids]))
        
        # --- 2. å¤„ç†æ–‡æœ¬ç‰¹å¾ (3å±‚) ---
        print("   æ­£åœ¨å †å æ–‡æœ¬ç‰¹å¾...")
        self.register_buffer('bank_txt_l1', torch.stack([cache[p]['txt'][0] for p in sorted_pids]))
        self.register_buffer('bank_txt_l2', torch.stack([cache[p]['txt'][1] for p in sorted_pids]))
        self.register_buffer('bank_txt_l3', torch.stack([cache[p]['txt'][2] for p in sorted_pids]))
        
        # --- 3. å¤„ç† Mask ---
        # å‡è®¾ä½ åœ¨æå–è„šæœ¬é‡ŒåŠ äº† mask
        if 'mask' in cache[sorted_pids[0]]:
            print("   æ­£åœ¨å †å  Mask...")
            self.register_buffer('bank_mask', torch.stack([cache[p]['mask'] for p in sorted_pids]))
        else:
            self.bank_mask = None
            
        print("âœ… ç‰¹å¾å·²å…¨éƒ¨é©»ç•™ GPUï¼")


        self.snr_diff_head = SNRDifficultyHead(feature_dim=256) # ç¡®ä¿ç»´åº¦æ˜¯ 256



        # å‡è®¾ feature_dim æ˜¯ 768
        self.img_proj_head = nn.Sequential(
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 128)  # é™ç»´åˆ° 128ï¼Œç®— Loss æ›´å¿«æ›´å‡†
        )

        self.txt_proj_head = nn.Sequential(
            nn.Linear(256, 256),
            nn.ReLU(),
            nn.Linear(256, 128)
        )
        self.gate = nn.Parameter(torch.tensor(0.0))


        pretrained_matrix = torch.load(KNOW_OUTPUT_FILE, map_location='cpu')
        
        # 3. åˆ›å»ºå†»ç»“çš„ Embedding å±‚ (ä½œä¸ºç‰¹å¾åº“)
        # freeze=True: ä¿æŒ BERT åŸå‘³è¯­ä¹‰ï¼Œä¸å‚ä¸å¾®è°ƒ (æ¨è)
        # freeze=False: å…è®¸ BERT ç‰¹å¾éšä»»åŠ¡å¾®è°ƒ (å®¹æ˜“è¿‡æ‹Ÿåˆï¼Œä¸æ¨è)
        self.know_bert_emb = nn.Embedding.from_pretrained(pretrained_matrix, freeze=True)
        
        # 4. ç»´åº¦æŠ•å½±å±‚ (768 -> 256)
        # è¿™ä¸ªå±‚æ˜¯éšæœºåˆå§‹åŒ–çš„ï¼Œä¹Ÿæ˜¯ä¹‹åå”¯ä¸€éœ€è¦è®­ç»ƒçš„éƒ¨åˆ†
        self.know_projector = nn.Linear(768, 256)

        # åœ¨ __init__ é‡Œ
        self.aux_classifier = nn.Linear(256, self.know_bert_emb.num_embeddings) # 86
        # 1. æ”¹è‰¯ç‰ˆ Gate: ä¸å˜ç»“æ„ï¼Œä½†æˆ‘ä»¬è¦æ”¹å®ƒçš„è¾“å‡ºå±‚åˆå§‹åŒ–
        self.se_gate = nn.Sequential(
            nn.Linear(self.knowledge_dim, self.knowledge_dim // 2), # ç¨å¾®å®½ä¸€ç‚¹ï¼Œä¿ç•™æ›´å¤šä¿¡æ¯
            nn.LayerNorm(self.knowledge_dim // 2), # åŠ ä¸ª Norm ç¨³å®šæ¢¯åº¦
            nn.ReLU(),
            nn.Linear(self.knowledge_dim // 2, self.knowledge_dim)
            # æ³¨æ„ï¼šè¿™é‡Œå»æ‰äº† Sigmoidï¼Œæˆ‘ä»¬æ”¾åœ¨ forward é‡ŒåŠ æ¸©åº¦æ§åˆ¶
        )
        
        # 2. ä¸ªæ€§åŒ– Alpha: å…è®¸æ›´å¤§çš„æ³¢åŠ¨
        self.alpha_net = nn.Linear(self.knowledge_dim, 1)
        self.diff_head_global = nn.Sequential(
            nn.Linear(self.FEATURE_DIM, self.DIFF_HIDDEN_DIM), # âœ… 768 -> 384
            nn.ReLU(),
            nn.Dropout(0.5),
            nn.Linear(self.DIFF_HIDDEN_DIM, 1)
        )
        
        self._init_weights()
    
    def _init_weights(self):
        """
        éå†æ‰€æœ‰å­æ¨¡å—ï¼Œè‡ªåŠ¨åˆå§‹åŒ–å¯è®­ç»ƒå‚æ•°ï¼š
        - Linear: xavier_uniform
        - Embedding: å‡åŒ€åˆå§‹åŒ–ï¼ˆçŸ¥è¯†ç‚¹ embedding å¯ä»¥ç”¨ normal æˆ– uniformï¼‰
        - LayerNorm: weight=1, bias=0
        - nn.Parameter: é»˜è®¤å€¼ä¿æŒåŸå§‹æˆ–å¯æŒ‡å®š
        """
        for m in self.modules():
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight)
                if m.bias is not None:
                    # é’ˆå¯¹è¾“å‡ºå±‚å’Œ diff_head bias åˆå§‹åŒ–ä¸ºå°è´Ÿå€¼
                    if m is self.prednet_full3 or m in [self.diff_head[-1], self.disc_head[-1]]:
                        nn.init.constant_(m.bias, -1.0)
                    else:
                        nn.init.zeros_(m.bias)
            elif isinstance(m, nn.Embedding):
                if hasattr(m, "is_knowledge_emb") and m.is_knowledge_emb:
                    nn.init.normal_(m.weight, mean=0.0, std=0.02)
                else:
                    nn.init.uniform_(m.weight, -0.05, 0.05)
            elif isinstance(m, nn.LayerNorm):
                nn.init.ones_(m.weight)
                nn.init.zeros_(m.bias)
        
        # çŸ¥è¯†ç‚¹åµŒå…¥ - å¢å¤§åˆå§‹åŒ–æ–¹å·®
     
        nn.init.xavier_normal_(self.W_p)
       
        
        # W_på‚æ•° - å¢å¤§åˆå§‹åŒ–æ–¹å·®  
        nn.init.normal_(self.W_p, mean=0, std=0.05)  # ä»0.02æ”¹ä¸º0.1
    
       
    
    
        
   

    # ======================================================
    # ğŸ› ï¸ ä½¿ç”¨æ–¹æ³• (åœ¨ forward å‡½æ•°ä¸­)
    # ======================================================
    def get_knowledge_embedding(self, knowledge_ids):
        """
        æ›¿ä»£åŸæ¥çš„ self.know_pro(knowledge_ids)
        input: knowledge_ids [Batch, ...] (ä¾‹å¦‚: 0, 5, 85)
        output: [Batch, ..., 256]
        """
        # 1. æŸ¥è¡¨è·å– 768 ç»´ BERT ç‰¹å¾
        bert_feats = self.know_bert_emb(knowledge_ids) # [Batch, 768]
        
        # 2. æŠ•å½±åˆ° 256 ç»´
        final_feats = self.know_projector(bert_feats)  # [Batch, 256]
        
        return final_feats
    def forward(self, batch):
        
        # --- ğŸ”§ å®šä¹‰ç›‘æ§å‡½æ•° (åªåœ¨ Rank 0 æ‰“å°) ---
        def check_mem(tag):
            if torch.distributed.get_rank() == 0 and self.training:
                # æ˜¾å­˜å•ä½ GB
                mem = torch.cuda.memory_allocated() / 1024**3
                print(f"   ğŸ’¾ [ç›‘æ§] {tag:<20}: {mem:.4f} GB")

        if torch.cuda.is_available():
            device = torch.device(f'cuda:{torch.cuda.current_device()}')
        else:
            device = torch.device('cpu')
        
        
        stu_id = batch['student_ids'].long().to(device)
        exer_id = batch['problem_ids'].long().to(device)
        kn_emb = batch['knowledges'].to(device)


         # ------------------------------------------------------------------
        # 1. NCDM åŸºç¡€éƒ¨åˆ†
        # ------------------------------------------------------------------
        stu_emb = torch.sigmoid(self.student_emb(stu_id))
        e_discrimination = torch.sigmoid(self.e_discrimination_NCDM(exer_id)) * 10
        k_difficulty = torch.sigmoid(self.k_difficulty_NCDM(exer_id))
        
        pids = batch['problem_ids'].long().to(self.bank_img_l1.device)
        
     
        img_raw_list = [
            self.bank_img_l1[pids], # [Batch, C, H, W]
            self.bank_img_l2[pids],
            self.bank_img_l3[pids],
            self.bank_img_l4[pids]
        ]
        
        txt_raw_list = [
            self.bank_txt_l1[pids],
            self.bank_txt_l2[pids],
            self.bank_txt_l3[pids]
        ]
        
        # å¤„ç† Mask
        if self.bank_mask is not None:
            raw_mask = self.bank_mask[pids]
            padding_mask = (raw_mask == 0)
        else:
            padding_mask = None
        
        # 1. æ‰¾å‡ºä¸é‡å¤çš„é¢˜ç›® ID
        # unique_pids: [Unique_Count] (ä¾‹å¦‚ 300ä¸ª)
        # inverse_indices: [Batch_Size] (ä¾‹å¦‚ 512ä¸ª)ï¼Œè®°å½•äº†åŸbatchæ¯ä¸ªæ ·æœ¬å¯¹åº”ç¬¬å‡ ä¸ªuniqueé¢˜ç›®
        unique_pids, inverse_indices = torch.unique(exer_id, sorted=True, return_inverse=True)
        
        # 2. æ‰¾å‡ºè¿™äº›å”¯ä¸€é¢˜ç›®åœ¨åŸ Batch ä¸­çš„â€œä»£è¡¨â€ä½ç½®ç´¢å¼•
        # åŸç†ï¼šæˆ‘ä»¬ä¸éœ€è¦æŠŠæ‰€æœ‰ 512 ä¸ªå›¾éƒ½æ‹¿æ¥ç®—ï¼Œåªéœ€è¦æ‹¿é‚£ 300 ä¸ªâ€œä»£è¡¨â€å»ç®—
        perm = torch.arange(inverse_indices.size(0), dtype=inverse_indices.dtype, device=inverse_indices.device)
        # scatter æ“ä½œï¼šåé¢çš„ç´¢å¼•ä¼šè¦†ç›–å‰é¢çš„ï¼Œå¾—åˆ°æ¯ä¸ª unique ID æœ€åä¸€æ¬¡å‡ºç°çš„ä½ç½®
        unique_indices = perm.new_empty(unique_pids.size(0)).scatter_(0, inverse_indices, perm)
        
        # 3. ã€ç­›é€‰ã€‘æ ¹æ®ç´¢å¼•ï¼Œåªåˆ‡åˆ†å‡ºé‚£ 300 ä¸ªæ ·æœ¬çš„ç‰¹å¾
        # img_raw_list æ˜¯ä¸€ä¸ªåˆ—è¡¨ï¼Œé‡Œé¢æ˜¯ GPU ä¸Šçš„ Tensorï¼Œç›´æ¥åˆ‡ç‰‡å¾ˆå¿«
        unique_img_raw = [t[unique_indices] for t in img_raw_list] 
        unique_txt_raw = [t[unique_indices] for t in txt_raw_list]
        
        # Mask ä¹Ÿè¦åˆ‡
        if padding_mask is not None:
            unique_padding_mask = padding_mask[unique_indices]
        else:
            unique_padding_mask = None

        # =========================================================
        # 4. ã€è®¡ç®—ã€‘ç‰¹å¾æå–ä¸èåˆ (åªè·‘ 300 æ¬¡ï¼çœç®—åŠ›ï¼çœæ˜¾å­˜ï¼)
        # =========================================================
        
        unique_kn_labels = kn_emb[unique_indices].float() # [Unique_Count, 86]




        # è¾“å…¥å½¢çŠ¶: [300, ...] -> è¾“å‡ºå½¢çŠ¶: [300, 256]
        unique_fused_feat , final_img_rep, final_txt_rep= self.update_features(unique_img_raw, unique_txt_raw, unique_padding_mask)
        

        problem_feat = unique_fused_feat[inverse_indices]
      
        
        mse_loss = torch.tensor(0.0, device=device)
        problem_feat = F.layer_norm(problem_feat, problem_feat.shape[-1:])
        F_j = problem_feat # [B, N, D]
        

        
        batch_indices, knowledge_indices = torch.nonzero(kn_emb, as_tuple=True)
        batch_size = kn_emb.shape[0]
        total_knowledge = self.know_bert_emb.num_embeddings
        modality_k_difficulty = torch.zeros(batch_size, total_knowledge, device=device)
        if len(batch_indices) > 0:
            with torch.cuda.amp.autocast(enabled=False):
                W_p_safe = self.W_p.float()
                # =======================================================
                # ğŸš€ æ ¸å¿ƒä¿®æ”¹å¼€å§‹
                # =======================================================
                
                # 1. æŸ¥è¡¨è·å– 768 ç»´çš„ BERT åŸç”Ÿç‰¹å¾
                # knowledge_indices å°±æ˜¯ [0, 5, 12...] è¿™ç§ ID
                raw_bert_emb = self.know_bert_emb(knowledge_indices) # [K, 768]
                
                # 2. æŠ•å½±åˆ° 256 ç»´
                # è¿™æ · selected_knowledge å°±æ˜¯ [K, 256] äº†ï¼Œå’Œä½ æƒ³è¦çš„ç»´åº¦ä¸€è‡´
                selected_knowledge = self.know_projector(raw_bert_emb) 
                
                # å½’ä¸€åŒ– (ä¿æŒä½ åŸæœ‰çš„é€»è¾‘)
                selected_knowledge = F.normalize(selected_knowledge, p=2, dim=-1)

                
                
                # çŸ©é˜µä¹˜æ³•
                intermediate = torch.matmul(selected_knowledge, W_p_safe)
                intermediate = F.layer_norm(intermediate, intermediate.shape[-1:])
                
               

                selected_F_j = F_j[batch_indices].float()
                
                # Attention è®¡ç®—
                W_j_selected = torch.bmm(selected_F_j, intermediate.unsqueeze(-1)).squeeze(-1)
                U_j_selected = torch.bmm(W_j_selected.unsqueeze(1), selected_F_j).squeeze(1)
                U_j_selected = F.layer_norm(U_j_selected, U_j_selected.shape[-1:])
                
               
                
                # Dropout + DiffHead
                #U_j_selected = F.dropout(U_j_selected, p=0.3, training=self.training)
                linear_output = self.diff_head_k(U_j_selected)
                selected_difficulty_pred = torch.sigmoid(linear_output)

            # ç¦»å¼€å®‰å…¨åŒº
            selected_difficulty_pred = selected_difficulty_pred.to(modality_k_difficulty.dtype)
            modality_k_difficulty[batch_indices, knowledge_indices] = selected_difficulty_pred.squeeze(1)

        alpha = torch.sigmoid(self.gate) 
        
        
        
       

       
        if self.training:
            mod_diff_drop = F.dropout(modality_k_difficulty, p=0.2) # 30% æ¦‚ç‡ä¸¢å¼ƒç‰¹å¾
        else:
            mod_diff_drop = modality_k_difficulty
        
       
       
      
        # æ ‡å‡†çš„åŠ æƒèåˆï¼Œä¸éœ€è¦å†æé‚£ä¸ª mask_keep_id äº†
        f_k_difficulty =1.0* modality_k_difficulty + 0.0* k_difficulty
        
        
        # [A] äº¤äº’è¾“å…¥ï¼šä½¿ç”¨ stu_raw å’Œ fused_difficulty_logits
        stu_raw = self.student_emb(stu_id)     
        raw_interaction = stu_raw * f_k_difficulty
        
        # [B] è®¡ç®—é—¨æ§ Logits
        gate_logits = self.se_gate(f_k_difficulty)
        
        # [C] æ¸©åº¦é”åŒ–
        channel_weights = torch.sigmoid(gate_logits * 5.0)
        
        # [D] åŠ æƒäº¤äº’
        clean_interaction = raw_interaction * channel_weights
        
        # [E] è®¡ç®—ä¸ªæ€§åŒ–æ•æ„Ÿåº¦ Alpha
        alpha_logit = self.alpha_net(clean_interaction)
        alpha_sensitivity = 1.0 + 0.4 * torch.tanh(alpha_logit/2.0)
        

        loss_reg = torch.mean(torch.abs(channel_weights - 0.5)) * -0.01 + torch.mean(alpha_logit ** 2) * 0.01
        
        # [F] æ³¨å…¥ NCDM
        # æ ¸å¿ƒï¼šåŒºåˆ†åº¦ * (èƒ½åŠ›-éš¾åº¦) * æ•æ„Ÿåº¦ * mask
        core_term = stu_emb - f_k_difficulty
        input_x_final = e_discrimination * (core_term * alpha_sensitivity) * kn_emb
        
        #input_x_final = e_discrimination * (stu_emb - f_k_difficulty) * kn_emb
        input_x_final = self.drop_1(torch.sigmoid(self.prednet_full1(input_x_final)))
        input_x_final = self.drop_2(torch.sigmoid(self.prednet_full2(input_x_final)))
        pred_final = self.prednet_full3(input_x_final)

        pred_final = torch.clamp(pred_final, min=-10.0, max=10.0) # é˜²çˆ†

        #loss_reg=torch.tensor(0.0, device=device)
        return pred_final, loss_reg, loss_reg, loss_reg
        
        '''
        alpha = torch.sigmoid(self.gate) 
        
        
        
       

        # =========================================================
        # ğŸš€ æ ¸å¿ƒä¿®æ”¹ï¼šå¹¶è¡Œè®¡ç®—ä¸‰æ¡é€šè·¯ (Multi-Head)
        # =========================================================

        # --- é€šè·¯ 1: çº¯ ID é¢„æµ‹ (ä¿è¯ ID èƒ½å¤Ÿæ­£å¸¸çƒ­å¯åŠ¨ï¼Œç»´æŒ 0.78 çš„åŸºå‡†) ---
        input_x_id = e_discrimination * (stu_emb - k_difficulty) * kn_emb
        input_x_id = self.drop_1(torch.sigmoid(self.prednet_full1(input_x_id)))
        input_x_id = self.drop_2(torch.sigmoid(self.prednet_full2(input_x_id)))
        pred_id = self.prednet_full3(input_x_id)
        #pred_id = self.output_layer(input_x_id)
        pred_id = torch.clamp(pred_id, min=-10.0, max=10.0) # é˜²çˆ†

        # --- é€šè·¯ 2: çº¯æ¨¡æ€ é¢„æµ‹ (å¼ºè¿«å›¾åƒåˆ†æ”¯ç‹¬ç«‹å¹²æ´»ï¼Œä¸è®¸å·æ‡’ï¼) ---
        # ğŸ’¡ Trick: è¿™é‡ŒåŠ ä¸€ä¸ª Dropoutï¼Œé˜²æ­¢æ¨¡æ€æ­»è®°ç¡¬èƒŒ (è§£å†³ Visual ID é—®é¢˜)
        if self.training:
            mod_diff_drop = F.dropout(modality_k_difficulty, p=0.2) # 30% æ¦‚ç‡ä¸¢å¼ƒç‰¹å¾
        else:
            mod_diff_drop = modality_k_difficulty
            
        input_x_img = e_discrimination * (stu_emb - mod_diff_drop) * kn_emb
        #pred_img = self.output_layer(input_x_img)
        input_x_img = self.drop_1(torch.sigmoid(self.prednet_full1(input_x_img)))
        input_x_img = self.drop_2(torch.sigmoid(self.prednet_full2(input_x_img)))
        pred_img = self.prednet_full3(input_x_img)
        pred_img = torch.clamp(pred_img, min=-10.0, max=10.0) # é˜²çˆ†

        # --- é€šè·¯ 3: èåˆ é¢„æµ‹ (æœ€ç»ˆç»“æœ) ---
        alpha = torch.sigmoid(self.gate)
        # æ ‡å‡†çš„åŠ æƒèåˆï¼Œä¸éœ€è¦å†æé‚£ä¸ª mask_keep_id äº†
        f_k_difficulty = 0.2 * modality_k_difficulty + 0.8 * k_difficulty
        
        
        # [A] äº¤äº’è¾“å…¥ï¼šä½¿ç”¨ stu_raw å’Œ fused_difficulty_logits
        stu_raw = self.student_emb(stu_id)     
        raw_interaction = stu_raw * f_k_difficulty
        
        # [B] è®¡ç®—é—¨æ§ Logits
        gate_logits = self.se_gate(f_k_difficulty)
        
        # [C] æ¸©åº¦é”åŒ–
        channel_weights = torch.sigmoid(gate_logits * 5.0)
        
        # [D] åŠ æƒäº¤äº’
        clean_interaction = raw_interaction * channel_weights
        
        # [E] è®¡ç®—ä¸ªæ€§åŒ–æ•æ„Ÿåº¦ Alpha
        alpha_logit = self.alpha_net(clean_interaction)
        alpha_sensitivity = 1.0 + torch.tanh(alpha_logit) * 2.0 
        
        # =========================================================
        # ğŸŸ¢ è¡¥å› Loss Reg Calculation
        # =========================================================
        # 1. channel_weights - 0.5 çš„ç»å¯¹å€¼è¶Šå¤§è¶Šå¥½ (é€¼è¿‘0æˆ–1) -> ä¹˜ä»¥è´Ÿå·æœ€å°åŒ–
        # 2. alpha_logit è¶Šå°è¶Šå¥½ (é˜²æ­¢çˆ†ç‚¸)
        loss_reg = torch.mean(torch.abs(channel_weights - 0.5)) * -0.01 + torch.mean(alpha_logit ** 2) * 0.01
        
        # [F] æ³¨å…¥ NCDM
        # æ ¸å¿ƒï¼šåŒºåˆ†åº¦ * (èƒ½åŠ›-éš¾åº¦) * æ•æ„Ÿåº¦ * mask
        core_term = stu_emb - f_k_difficulty
        input_x_final = e_discrimination * (core_term * alpha_sensitivity) * kn_emb
        
        #input_x_final = e_discrimination * (stu_emb - f_k_difficulty) * kn_emb
        input_x_final = self.drop_1(torch.sigmoid(self.prednet_full1(input_x_final)))
        input_x_final = self.drop_2(torch.sigmoid(self.prednet_full2(input_x_final)))
        pred_final = self.prednet_full3(input_x_final)

        #pred_final = self.output_layer(input_x_final)
        pred_final = torch.clamp(pred_final, min=-10.0, max=10.0) # é˜²çˆ†

        # =========================================================
        # ğŸ—‘ï¸ æ¸…ç†: åˆ æ‰åŸæ¥é‚£äº› mse_loss, loss_img, loss_txt çš„è®¡ç®—
        # æˆ‘ä»¬æŠŠ Loss çš„è®¡ç®—å…¨éƒ¨ç§»åˆ°å¤–é¢å»ï¼Œä¿æŒ Model å¹²å‡€
        # =========================================================
        

       
        # è¿”å› 3 ä¸ªé¢„æµ‹å€¼ + Gateå€¼
        # pred_final: ä¸»é¢„æµ‹
        # pred_id:    è¾…åŠ© ID é¢„æµ‹
        # pred_img:   è¾…åŠ© æ¨¡æ€ é¢„æµ‹
        return pred_final, pred_id, pred_img, alpha
        '''
       
        '''
        if self.training:
            # 1. æ‹¿åˆ°é‚£äº› "Unique é¢˜ç›®" çš„çŸ¥è¯†ç‚¹
            # kn_emb æ˜¯å…¨ Batch çš„ (æ¯”å¦‚ 512 ä¸ª)
            # æˆ‘ä»¬éœ€è¦å»é‡åçš„ (æ¯”å¦‚ 300 ä¸ª)ï¼Œç”¨æ¥è·Ÿ final_img_rep (300ä¸ª) å¯¹åº”
            # unique_indices æ˜¯ä½ åœ¨å‰é¢å»é‡æ­¥éª¤é‡Œç”Ÿæˆçš„ (å°±æ˜¯é‚£ä¸ª scatter ä¹‹å‰ç®—å‡ºæ¥çš„ç´¢å¼•)
            unique_kn = kn_emb[unique_indices].float() 
            
            # 2. åˆ¶ä½œæ­£æ ·æœ¬ Mask (åªè¦æœ‰ 1 ä¸ªçŸ¥è¯†ç‚¹ç›¸åŒï¼Œå°±è®¤ä¸ºæ˜¯åŒç±»)
            # [300, K] @ [K, 300] -> [300, 300]
            sim_matrix = torch.matmul(unique_kn, unique_kn.T)
            pos_mask = (sim_matrix > 3).float() 
            
            # 3. ç®— Loss (è°ƒç”¨ä¸‹é¢é‚£ä¸ªå‡½æ•°)
            # final_img_rep æ˜¯ä½ åœ¨ update_features é‡Œå•ç‹¬åå‡ºæ¥çš„çº¯å›¾åƒç‰¹å¾
            loss_img = self.compute_supcon_loss(final_img_rep, pos_mask)
            
            # final_txt_rep æ˜¯çº¯æ–‡æœ¬ç‰¹å¾
            loss_txt = self.compute_supcon_loss(final_txt_rep, pos_mask)
            
            # 4. åŠ æƒå¾—åˆ°æœ€ç»ˆè¾…åŠ© Loss
            mse_loss = 0.5 * loss_img + 0.5 * loss_txt
        '''
        
        '''
        # 2. åªåœ¨è®­ç»ƒæ—¶è®¡ç®—è¾…åŠ© Loss
        if self.training:
            # å…³é”®ä¸€æ­¥ï¼šåªæŠŠã€çº¯å›¾åƒç‰¹å¾ã€‘æ‰”è¿›å»é¢„æµ‹
            # final_img_rep æ˜¯ [Unique_Count, 256]
            k_pred_logits = self.aux_classifier(final_img_rep) 
            
            # è®¡ç®— BCE Loss (å¤šæ ‡ç­¾åˆ†ç±»)
            # è®©æ¨¡å‹å­¦ä¼šï¼šè¿™å¼ å›¾é‡Œç”»äº†ä»€ä¹ˆï¼Œå°±å¯¹åº”ä»€ä¹ˆçŸ¥è¯†ç‚¹
            aux_loss = F.binary_cross_entropy_with_logits(k_pred_logits, unique_kn_labels)
            
            # èµ‹å€¼ç»™ mse_loss
            # (è¿™æ ·ä½ åœ¨å¤–é¢çš„ train_epoch é‡Œå†™çš„ loss = main + 0.2 * mse_loss å°±èƒ½ç”Ÿæ•ˆäº†)
            mse_loss = aux_loss 
        '''
        # ğŸ‘†ğŸ‘†ğŸ‘† [ä¿®æ”¹ä»£ç ç»“æŸ] ğŸ‘†ğŸ‘†ğŸ‘†

        
    def compute_supcon_loss(self, features, mask, temp=0.1):
        """
        è®¡ç®—å¯¹æ¯”æŸå¤±
        features: [N, Dim] (ä¾‹å¦‚ [300, 768])
        mask: [N, N] (0/1 çŸ©é˜µï¼Œè°å’Œè°æ˜¯åŒç±»)
        """
        # 1. å½’ä¸€åŒ– (ç®—ä½™å¼¦ç›¸ä¼¼åº¦å¿…é¡»åš)
        features = F.normalize(features, dim=1)
        
        # 2. ç®—ç›¸ä¼¼åº¦çŸ©é˜µ [N, N]
        logits = torch.matmul(features, features.T) / temp
        
        # 3. æ•°å€¼ç¨³å®š (å‡æœ€å¤§å€¼)
        logits_max, _ = torch.max(logits, dim=1, keepdim=True)
        logits = logits - logits_max.detach()
        
        # 4. æŠŠ"è‡ªå·±è·Ÿè‡ªå·±"çš„æƒ…å†µæŒ–æ‰ (å¯¹è§’çº¿è®¾ä¸º0)
        batch_size = features.shape[0]
        # ç”Ÿæˆå¯¹è§’çº¿ Mask
        eye_mask = torch.eye(batch_size, device=features.device)
        # åˆ†æ¯ mask: æ‰€æœ‰äººé™¤äº†è‡ªå·±
        denominator_mask = 1 - eye_mask
        # åˆ†å­ mask: æ­£æ ·æœ¬é™¤äº†è‡ªå·±
        numerator_mask = mask * denominator_mask
        
        # 5. ç®—å…¬å¼
        exp_logits = torch.exp(logits) * denominator_mask
        # log_prob = logits - log(sum(exp))
        log_prob = logits - torch.log(exp_logits.sum(1, keepdim=True) + 1e-6)
        
        # 6. åªç®—æ­£æ ·æœ¬çš„å¹³å‡ Loss
        # æœ‰æ­£æ ·æœ¬çš„è¡Œæ‰ç®—ï¼Œé˜²æ­¢é™¤ä»¥ 0
        mask_sum = numerator_mask.sum(1)
        mean_log_prob_pos = (numerator_mask * log_prob).sum(1) / (mask_sum + 1e-6)
        
        # æœ€ç»ˆ Loss
        loss = -mean_log_prob_pos[mask_sum > 0].mean()
        
        if torch.isnan(loss): return torch.tensor(0.0, device=features.device)
        return loss


    def load_all_features(self,TEXT_FEATURES_DIR):
        """ç›´æ¥åŠ è½½TEXT_FEATURES_DIRç›®å½•ä¸‹æ‰€æœ‰ç‰¹å¾æ–‡ä»¶"""
        features_dict = {}
        for file_path in TEXT_FEATURES_DIR.glob("*.pt"):
            pid = int(file_path.stem)  # æ–‡ä»¶åå°±æ˜¯pid
            features_dict[pid] = torch.load(file_path)
        return features_dict
        
    def know_diff(self, item_features, knowledge_mask):
        """
        çŸ¥è¯†ç‚¹æ„ŸçŸ¥çš„éš¾åº¦é¢„æµ‹æ–¹æ³•
        
        å‚æ•°:
        item_features: é¢˜ç›®ç‰¹å¾, shape [batch_size, input_dim]
        knowledge_mask: çŸ¥è¯†ç‚¹æ©ç , shape [batch_size, num_knowledge]
        
        è¿”å›:
        éš¾åº¦é¢„æµ‹å€¼, shape [batch_size, num_knowledge]
        """
        # 1. æŠ•å½±é¢˜ç›®ç‰¹å¾åˆ°åµŒå…¥ç©ºé—´
        item_emb = self.diff_item_proj(item_features)  # [batch_size, embed_dim]
        
        # 2. è·å–æ‰€æœ‰çŸ¥è¯†ç‚¹çš„åµŒå…¥
        knowledge_emb = self.diff_knowledge_emb.weight  # [num_knowledge, embed_dim]
        
        # 3. è®¡ç®—é¢˜ç›®ä¸æ‰€æœ‰çŸ¥è¯†ç‚¹çš„ç›¸ä¼¼åº¦ï¼ˆç‚¹ç§¯ï¼‰
        # [batch_size, embed_dim] @ [embed_dim, num_knowledge] -> [batch_size, num_knowledge]
        similarity = torch.matmul(item_emb, knowledge_emb.t())
        
        # 4. è°ƒæ•´åˆ†æ•°èŒƒå›´
        adjusted_scores = similarity * self.diff_scale + self.diff_bias
        
        # 5. è½¬æ¢ä¸º0-1ä¹‹é—´çš„æ¦‚ç‡å€¼ï¼ˆéš¾åº¦ï¼‰
        difficulty = torch.sigmoid(adjusted_scores)  # [batch_size, num_knowledge]
        
        # 6. åº”ç”¨æ©ç ï¼šä¸æ¶‰åŠçš„çŸ¥è¯†ç‚¹éš¾åº¦ç½®ä¸º0
        masked_difficulty = difficulty * knowledge_mask
        
        return masked_difficulty
    def know_disc(self, item_features, knowledge_mask):
        """
        çŸ¥è¯†ç‚¹æ„ŸçŸ¥çš„éš¾åº¦é¢„æµ‹æ–¹æ³•
        
        å‚æ•°:
        item_features: é¢˜ç›®ç‰¹å¾, shape [batch_size, input_dim]
        knowledge_mask: çŸ¥è¯†ç‚¹æ©ç , shape [batch_size, num_knowledge]
        
        è¿”å›:
        éš¾åº¦é¢„æµ‹å€¼, shape [batch_size, num_knowledge]
        """
        # 1. æŠ•å½±é¢˜ç›®ç‰¹å¾åˆ°åµŒå…¥ç©ºé—´
        item_emb = self.disc_item_proj(item_features)  # [batch_size, embed_dim]
        
        # 2. è·å–æ‰€æœ‰çŸ¥è¯†ç‚¹çš„åµŒå…¥
        knowledge_emb = self.disc_knowledge_emb.weight  # [num_knowledge, embed_dim]
        
        # 3. è®¡ç®—é¢˜ç›®ä¸æ‰€æœ‰çŸ¥è¯†ç‚¹çš„ç›¸ä¼¼åº¦ï¼ˆç‚¹ç§¯ï¼‰
        # [batch_size, embed_dim] @ [embed_dim, num_knowledge] -> [batch_size, num_knowledge]
        similarity = torch.matmul(item_emb, knowledge_emb.t())
        
        # 4. è°ƒæ•´åˆ†æ•°èŒƒå›´
        adjusted_scores = similarity * self.disc_scale + self.disc_bias
        
        # 5. è½¬æ¢ä¸º0-1ä¹‹é—´çš„æ¦‚ç‡å€¼ï¼ˆéš¾åº¦ï¼‰
        difficulty = torch.sigmoid(adjusted_scores)  # [batch_size, num_knowledge]
        
        # 6. åº”ç”¨æ©ç ï¼šä¸æ¶‰åŠçš„çŸ¥è¯†ç‚¹éš¾åº¦ç½®ä¸º0
        masked_difficulty = difficulty * knowledge_mask
        
        return masked_difficulty
    def disc(self, base_discrimination, frequency):
        """
        ä¿®æ”¹åçš„åŒºåˆ†åº¦è®¡ç®—å‡½æ•°
        è¾“å‡ºèŒƒå›´: (0, 10)
        """
        # 1. å¯¹é¢‘ç‡è¿›è¡Œæ¸©å’Œçš„éçº¿æ€§å˜æ¢ï¼Œé¿å…ä½¿ç”¨å¹‚æ¬¡å‚æ•°
        amplified_freq = torch.sigmoid((frequency - 0.5) * 10)  # å°†[0,1]æ˜ å°„åˆ°[0,1]ä½†æ›´é™¡å³­
        
        # 2. ä½¿ç”¨æ›´ç¨³å®šçš„ç»„åˆå…¬å¼
        # è®© base_scale æ§åˆ¶åŸºç¡€å€¼ï¼Œfreq_amplifier æ§åˆ¶é¢‘ç‡å½±å“å¼ºåº¦
        combined = self.base_scale * base_discrimination + self.freq_amplifier * amplified_freq
        
        # 3. ä½¿ç”¨sigmoidç¡®ä¿è¾“å‡ºåœ¨0-1èŒƒå›´å†…ï¼Œç„¶åç¼©æ”¾
        combined = torch.sigmoid(combined) * 10.0
        
        return combined



        
   
    def update_features(self, img_raw_list, txt_raw_list,padding_mask):
        """
        img_raw_list: [B, 256, 56, 56], ... (å·²åœ¨ GPU)
        txt_raw_list: [B, 80, 768], ... (å·²åœ¨ GPU)
        """
      
        
        # 2. èåˆ (Fusion)
        fused_out, final_img_rep, final_txt_rep = self.model_feat(img_raw_list, txt_raw_list,padding_mask)

        '''
        # 2. å‡†å¤‡ Checkpoint
        # åªæœ‰åœ¨è®­ç»ƒæ¨¡å¼ä¸‹æ‰å¼€å¯ Checkpoint
        if self.training:
            
            # âš ï¸ å…³é”®åŠ¨ä½œï¼šå› ä¸º img_vecs æ˜¯ä¸­é—´å˜é‡ï¼Œ
            # å¿…é¡»æ˜¾å¼å¼€å¯æ¢¯åº¦ï¼Œå¦åˆ™ checkpoint ä¼šæŠ¥é”™ï¼š
            # "element 0 of tensors does not require grad..."
            for t in img_raw_list:
                t.requires_grad_(True)
            for t in txt_raw_list:
                t.requires_grad_(True)
                
            # 3. ä½¿ç”¨ checkpoint åŒ…è£¹èåˆå±‚
            # self.fusion (æˆ– self.model_feat) æ˜¯ä½ å®šä¹‰çš„é‚£ä¸ªå¤§èåˆæ¨¡å—
            # use_reentrant=False æ˜¯ PyTorch æ–°ç‰ˆæ¨èå†™æ³•ï¼Œæ›´ç¨³å®š
            fused_out = checkpoint(
                self.model_feat, 
                img_raw_list, 
                txt_raw_list, 
                padding_mask, 
                use_reentrant=False
            )
            
        else:
            # éªŒè¯/æµ‹è¯•æ¨¡å¼ï¼Œæˆ–è€…ä¸è®­ç»ƒæ—¶ï¼Œæ­£å¸¸å‰å‘ä¼ æ’­
            fused_out = self.model_feat(img_raw_list, txt_raw_list, padding_mask)
        '''
        return fused_out, final_img_rep, final_txt_rep
        



    def print_mem(self,tag):
        allocated = torch.cuda.memory_allocated() / 1024**2
        reserved = torch.cuda.memory_reserved() / 1024**2
        print(f"[{tag}] Allocated: {allocated:.2f} MB | Reserved: {reserved:.2f} MB")

    def get_student_freq_tensor(self,csv_path):
        """
        è¯»å–å­¦ç”Ÿ-çŸ¥è¯†ç‚¹é¢‘ç‡çŸ©é˜µCSVï¼Œè¿”å›ä¸€ä¸ª (num_students, num_concepts) çš„Tensor
        ä»¥åŠä¸€ä¸ª user_id åˆ—è¡¨ï¼ˆæŒ‰é¡ºåºå¯¹é½ï¼‰
        """
        df = pd.read_csv(csv_path)
        df = pd.read_csv(csv_path)
        print(f"ğŸ“Š CSVåˆ—æ•°ï¼ˆé™¤user_idï¼‰: {df.shape[1] - 1}")
        print(f"ğŸ“Š CSVåˆ—åï¼ˆå‰å‡ åˆ—ï¼‰: {df.columns[:10].tolist()}")

        missing_cols = set(range(329)) - set(map(int, df.columns.drop(USER_ID_COL)))
        print(f"ğŸ§¨ ç¼ºå¤±çš„çŸ¥è¯†ç‚¹åˆ—ç´¢å¼•ï¼ˆç›¸å¯¹äº0~328ï¼‰: {missing_cols}")

        user_ids = df[USER_ID_COL].astype(str).tolist()  # è½¬æˆå­—ç¬¦ä¸²é˜²æ­¢åŒ¹é…å‡ºé”™
        freq_tensor = torch.tensor(df.drop(columns=[USER_ID_COL]).values, dtype=torch.float32)
        return freq_tensor, user_ids
    def get_student_weights(self, filepath, num_students):
        """
        ä» student_weights.csv æ–‡ä»¶ä¸­è¯»å–æƒé‡ï¼Œè¿”å›ä¸€ä¸ª tensorï¼š
        student_weights_tensor[user_id] = weight
        """
        df = pd.read_csv(filepath)

        if USER_ID_COL not in df.columns or 'Weight' not in df.columns:
            raise ValueError("CSV æ–‡ä»¶å¿…é¡»åŒ…å« 'UserId' å’Œ 'Weight' ä¸¤åˆ—ã€‚")

        # åˆå§‹åŒ–ä¸º 1ï¼ˆæˆ–ä½ è®¤ä¸ºçš„é»˜è®¤å€¼ï¼‰
        student_weights_tensor = torch.ones(num_students, dtype=torch.float32)

        for uid, weight in zip(df[USER_ID_COL], df['Weight']):
            if uid < num_students:
                student_weights_tensor[uid] = weight
            else:
                print(f"Warning: student ID {uid} è¶…å‡ºäº†æœ€å¤§èŒƒå›´ {num_students - 1}")

        return student_weights_tensor
    


    def htspd(self,theta, b, k=1.5, p=0.7, q=0.3):
        """
        è®¡ç®—åŒæ›²æ­£åˆ‡ç¬¦å·ä¿æŒå·®å€¼ï¼ˆHTSPDï¼‰
        è¾“å…¥ï¼š
            theta: å­¦ç”Ÿèƒ½åŠ›å¼ é‡ï¼Œå½¢çŠ¶ [B, K]
            b: é¢˜ç›®éš¾åº¦å¼ é‡ï¼Œå½¢çŠ¶ [B, K]
            k, p, q: è¶…å‚æ•°
        è¿”å›ï¼š
            delta: HTSPDå·®å€¼å¼ é‡ï¼Œå½¢çŠ¶ [B, K]
        """
        diff = theta - b                              # å·®å€¼
        sum_ = theta + b                              # å’Œ
        
        term1 = torch.tanh(k * diff)                  # tanh(k*(Î¸ - b))
        eps = 1e-6
        term2 = 1 + torch.clamp(torch.abs(diff), min=eps) ** p
        term3 = 1 + sum_**q                           # 1 + (Î¸ + b)^q
        

        delta = term1 * (term2 / term3)
        return delta



    def compute_contrastive_loss(self, problem_feat, kn_emb, k_difficulty, exer_id):
        """
        è®¡ç®—è‡ªç„¶å¯¹åº”å¯¹æ¯”æŸå¤±
        problem_feat: [B, max_len, 768] æ¨¡æ€ç‰¹å¾
        kn_emb: [B, knowledge_n] çŸ¥è¯†ç‚¹æ©ç 
        k_difficulty: [B, knowledge_n] é¢„æµ‹çš„éš¾åº¦
        exer_id: [B] é¢˜ç›®ID
        """
        batch_size = problem_feat.shape[0]
        
        # 1. æå–æ¯ä¸ªé¢˜ç›®çš„æ¨¡æ€è¡¨ç¤ºï¼ˆé€šè¿‡å¹³å‡æ± åŒ–ï¼‰
        modal_embeddings = torch.mean(problem_feat, dim=1)  # [B, 768]
        modal_embeddings = F.normalize(modal_embeddings, p=2, dim=1)  # L2å½’ä¸€åŒ–
        
        # 2. è®¡ç®—æ¨¡æ€ç›¸ä¼¼åº¦çŸ©é˜µ
        modal_sim_matrix = torch.mm(modal_embeddings, modal_embeddings.t())  # [B, B]
        
        # 3. è®¡ç®—éš¾åº¦ç›¸ä¼¼åº¦çŸ©é˜µ (1 - éš¾åº¦å·®å¼‚)
        # ä½¿ç”¨æ¯ä¸ªé¢˜ç›®ä¸»è¦è€ƒå¯Ÿçš„çŸ¥è¯†ç‚¹éš¾åº¦
        primary_knowledge = self.get_exercise_difficulty(kn_emb, k_difficulty)  # [B]
        difficulty_sim_matrix = 1 - torch.abs(
            primary_knowledge.unsqueeze(1) - primary_knowledge.unsqueeze(0)
        )  # [B, B]
        
        # 4. åˆ›å»ºçŸ¥è¯†ç‚¹æ©ç  (åŒä¸€çŸ¥è¯†ç‚¹ä¸º1)
        kp_mask = self.create_knowledge_point_mask(kn_emb)  # [B, B]
        
        return self.natural_contrastive_loss(
            modal_sim_matrix, difficulty_sim_matrix, kp_mask
        )

    def get_exercise_difficulty(self, kn_emb, k_difficulty):
        sum_diff = (kn_emb * k_difficulty).sum(dim=1)
        count = kn_emb.sum(dim=1).clamp(min=1)
        return sum_diff / count

    def create_knowledge_point_mask(self, kn_emb):
        kp_mask = (torch.mm(kn_emb, kn_emb.t()) > 0).float()
        kp_mask.fill_diagonal_(0)
        return kp_mask

    def natural_contrastive_loss(self, modal_sim, difficulty_sim, kp_mask):
        """ä½¿ç”¨è¿™ä¸ªç‰ˆæœ¬ - ç®€å•å¿«é€Ÿä¸”æœ‰æ•ˆ"""
        modal_sim = (modal_sim + 1) / 2  # å½’ä¸€åŒ–åˆ°[0,1]
        valid_mask = kp_mask > 0
        if valid_mask.sum() == 0:
            return torch.tensor(0.0, device=modal_sim.device)
        return F.mse_loss(modal_sim[valid_mask], difficulty_sim[valid_mask])


    def print_memory(self,tag=""):
        allocated = torch.cuda.memory_allocated() / 1024**2  # MB
        reserved = torch.cuda.memory_reserved() / 1024**2    # MB
        print(f"[{tag}] allocated: {allocated:.2f} MB, reserved: {reserved:.2f} MB")





    def apply_clipper(self):
        """
        åº”ç”¨éè´Ÿæˆªæ–­ï¼ˆå°†ç½‘ç»œå‚æ•°é™åˆ¶ä¸ºéè´Ÿï¼‰ã€‚
        """
        clipper = NoneNegClipper()
        self.prednet_full1.apply(clipper)
        self.prednet_full2.apply(clipper)
        self.prednet_full3.apply(clipper)

    def get_knowledge_status(self, stu_id):
        """
        è·å–å­¦ç”Ÿçš„çŸ¥è¯†çŠ¶æ€ã€‚

        :param stu_id: LongTensor, å­¦ç”Ÿ ID çš„ç´¢å¼•
        :return: Tensor, å­¦ç”Ÿçš„çŸ¥è¯†çŠ¶æ€å‘é‡
        """
        stat_emb = torch.sigmoid(self.student_emb(stu_id))
        return stat_emb.data  # è¿”å›çŸ¥è¯†çŠ¶æ€

    def get_exer_params(self, exer_id):
        """
        è·å–ç»ƒä¹ é¢˜çš„å‚æ•°ï¼ˆçŸ¥è¯†ç‚¹éš¾åº¦å’ŒåŒºåˆ†åº¦ï¼‰ã€‚

        :param exer_id: LongTensor, ç»ƒä¹ é¢˜ ID çš„ç´¢å¼•
        :return: Tuple[Tensor, Tensor], åˆ†åˆ«ä¸ºçŸ¥è¯†ç‚¹éš¾åº¦å’ŒåŒºåˆ†åº¦
        """
        k_difficulty = torch.sigmoid(self.feature_to_difficulty(exer_id))
        e_discrimination = torch.sigmoid(self.feature_to_discrimination(exer_id)) * 10
        return k_difficulty.data, e_discrimination.data  # è¿”å›ç»ƒä¹ é¢˜å‚æ•°


class NoneNegClipper(object):
    """
    è‡ªå®šä¹‰çš„éè´Ÿæˆªæ–­å™¨ï¼Œç”¨äºç¡®ä¿æƒé‡å‚æ•°ä¸ºéè´Ÿå€¼ã€‚
    """
    def __init__(self):
        super(NoneNegClipper, self).__init__()

    def __call__(self, module):
        """
        é’ˆå¯¹æ¨¡å—çš„æƒé‡å‚æ•°ï¼Œåº”ç”¨éè´Ÿæˆªæ–­ã€‚

        :param module: nn.Module, éœ€è¦å¤„ç†çš„æ¨¡å—
        """
        if hasattr(module, 'weight'):  # æ£€æŸ¥æ¨¡å—æ˜¯å¦æœ‰ 'weight' å±æ€§
            w = module.weight.data
            # è®¡ç®—è´Ÿå€¼éƒ¨åˆ†ï¼ˆå¦‚æœå°äºé›¶åˆ™å–åï¼‰
            a = torch.relu(torch.neg(w))
            # è´Ÿå€¼éƒ¨åˆ†åŠ å›ï¼Œç¡®ä¿æƒé‡éè´Ÿ
            w.add_(a)