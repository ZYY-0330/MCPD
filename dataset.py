import json
import numpy as np
import torch
import pandas as pd
from pathlib import Path
from PIL import Image
from torch.utils.data import Dataset
from configs.dataset_config import *
import torch
import torch_geometric as pyg
from torch_geometric.data import HeteroData
from configs.dataset_config import *
from collections import defaultdict
from transformers import AutoTokenizer, AutoModel
import h5py
from torch.utils.data import DataLoader
import os
from torch.multiprocessing import get_context  # æ–°å¢
import torch.nn.functional as F
from scipy.sparse import lil_matrix
from scipy.stats import pearsonr
import itertools
import torch
import torch.nn as nn  # æ·»åŠ è¿™è¡Œå¯¼å…¥
import torch
from torch.utils.data import Dataset
import pandas as pd
import json
import os
from pathlib import Path
import torch.distributed as dist
from configs.dataset_config import * # å‡è®¾ä½ çš„é…ç½®éƒ½åœ¨è¿™é‡Œ

import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import os
import torch.distributed as dist
from pathlib import Path
from configs.dataset_config import *

import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import os
import torch.distributed as dist
from pathlib import Path
from configs.dataset_config import *

import torch
from torch.utils.data import Dataset, DataLoader
import pandas as pd
import os
import torch.distributed as dist
from pathlib import Path
from configs.dataset_config import *

# ============================================================================
# 1. ProblemDataset (åªè´Ÿè´£æŸ¥ç¦»çº¿å­—å…¸)
# ============================================================================
class ProblemDataset(Dataset):
    def __init__(self, feature_cache_path=None):
        """
        :param feature_cache_path: ç¦»çº¿ç‰¹å¾æ–‡ä»¶çš„è·¯å¾„
        """
        # ä½¿ç”¨é…ç½®ä¸­çš„è·¯å¾„ï¼Œæˆ–è€…ä¼ å…¥çš„è·¯å¾„
        self.feature_cache_path = OUTPUT_FILE
        
        self._init_paths()
        self._load_data()
        self._validate_problems()
        self._build_knowledge_dict()

    def _init_paths(self):
        self.knowledge_path = Path(RAW_DATA['knowledge'])

    def _load_data(self):
        # 1. åŠ è½½çŸ¥è¯†ç‚¹CSV
        print(f"Loading knowledge from {self.knowledge_path}...")
        self.knowledge_df = pd.read_csv(self.knowledge_path)
        '''
        # 2. åŠ è½½ç¦»çº¿ç‰¹å¾ PT æ–‡ä»¶
        if not os.path.exists(self.feature_cache_path):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç¦»çº¿ç‰¹å¾æ–‡ä»¶: {self.feature_cache_path}ï¼Œè¯·å…ˆè¿è¡Œ run_extraction.pyï¼")

        rank = dist.get_rank() if (dist.is_available() and dist.is_initialized()) else 0
        print(f"âš¡ [Rank {rank}] æ­£åœ¨æŠŠç¦»çº¿ç‰¹å¾åŠ è½½è¿›å†…å­˜: {self.feature_cache_path} ...")
        
        # map_location='cpu' æ˜¯å…³é”®ï¼Œä¸å æ˜¾å­˜
        self.features_dict = torch.load(self.feature_cache_path, map_location='cpu')
        
        print(f"âœ… ç‰¹å¾åŠ è½½å®Œæˆï¼ŒåŒ…å« {len(self.features_dict)} ä¸ªé¢˜ç›®ã€‚")

        if dist.is_available() and dist.is_initialized():
            dist.barrier()
        '''
    def _validate_problems(self):
        knowledge_ids = set(map(int, self.knowledge_df[PROBLEM_ID_COL]))
        
        # 3. ç”Ÿæˆæœ‰æ•ˆåˆ—è¡¨ (ç›´æ¥ä½¿ç”¨ knowledge_ids)
        self.valid_pids = sorted(
            knowledge_ids,
            key=lambda x: int(x)
        )
        
        print(f"å”¯ä¸€æœ‰æ•ˆé¢˜ç›®æ•°é‡ (ä»…åŸºäºçŸ¥è¯†ç‚¹): {len(self.valid_pids)}")

    def _build_knowledge_dict(self):
        print("æ­£åœ¨æ„å»ºçŸ¥è¯†ç‚¹å­—å…¸...")
        self.knowledge_dict = {}
        for pid in self.valid_pids:
            self.knowledge_dict[int(pid)] = self._get_knowledge_vector(pid)

    def _get_knowledge_vector(self, pid):
        try:
            skills = self.knowledge_df[
                self.knowledge_df[PROBLEM_ID_COL] == int(pid)
            ][SKILL_ID_COL].iloc[0]
            
            if isinstance(skills, str):
                skills = eval(str(skills).replace('"', ''))
            
            vector = torch.zeros(TOTAL_SKILLS)
            vector[torch.tensor(skills)] = 1
            return vector
        except Exception as e:
            # print(f"çŸ¥è¯†ç‚¹ç”Ÿæˆå¤±è´¥: {pid}")
            return torch.zeros(TOTAL_SKILLS)

    # --- ä¾› RecordDataset è°ƒç”¨çš„æ¥å£ ---
    def get_features(self, pid):
        """è¿”å› (img_list, txt_list, mask)"""
        pid = int(pid)
        feats = self.features_dict[pid]
        return feats['img'], feats['txt'], feats['mask']

    def get_knowledge(self, pid):
        return self.knowledge_dict[int(pid)]

    def __len__(self):
        return len(self.valid_pids)

    def __getitem__(self, idx):
        pid = self.valid_pids[idx]
        feats = self.features_dict[pid]
        return {
            'problem_id': int(pid),
            'img_raw': feats['img'], 
            'txt_raw': feats['txt'],
            'txt_mask': feats['mask'],
            'knowledge': self.knowledge_dict[int(pid)]
        }
    
    def get_skill_to_problems(self):
        skill_to_problems = {i: [] for i in range(TOTAL_SKILLS)}
        for pid in self.valid_pids:
            knowledge_vec = self.knowledge_dict[int(pid)]
            for skill_id in torch.nonzero(knowledge_vec).squeeze(1).tolist():
                skill_to_problems[skill_id].append(int(pid))
        return skill_to_problems


# ============================================================================
# 2. RecordDataset (åŒ…å«è‡ªå®šä¹‰ Collate_fn)
# ============================================================================
class RecordDataset(Dataset):
    def __init__(self, mode='train', rank=None):
        self.mode = mode
        # åˆå§‹åŒ–ä¸Šé¢çš„ ProblemDatasetï¼Œè‡ªåŠ¨åŠ è½½å†…å­˜
        self.problem_data = ProblemDataset(feature_cache_path=OUTPUT_FILE)
        
        print(f"ğŸš€ [RecordDataset] æ­£åœ¨åˆå§‹åŒ– {mode} é›†...")
        self._load_records()
        self._validate_records()
        # self._build_exer_kn_graph() # æŒ‰éœ€ä¿ç•™
        self.rank = rank

    def _load_records(self):
        file_path = Path(RAW_DATA[self.mode])
        self.records = pd.read_csv(file_path)
        
        # å…¼å®¹ä¸åŒæ ¼å¼çš„ USER_ID
        user_ids = set(map(str, self.records[USER_ID_COL]))
        self.user_n = len(user_ids)

    def _validate_records(self):
        valid_pids = set(self.problem_data.valid_pids)
        self.records = self.records[
            self.records[PROBLEM_ID_COL].astype(int).isin(valid_pids)
        ]
        print(f"[{self.mode}] æœ‰æ•ˆè®°å½•: {len(self.records)}")

    def __len__(self):
        return len(self.records)

    def __getitem__(self, idx):
        record = self.records.iloc[idx]
        pid = int(record[PROBLEM_ID_COL])
        # ç¡®ä¿ student_id è½¬ä¸º int (å¦‚æœæ˜¯ Embedding éœ€è¦)
        try:
            raw_stu_id = int(record[USER_ID_COL]) 
        except:
            # å¦‚æœ ID æ˜¯å­—ç¬¦ä¸²hashï¼Œéœ€è¦å¤–éƒ¨å¤„ç†æ˜ å°„ï¼Œè¿™é‡Œå‡è®¾æ˜¯ int
            raw_stu_id = int(record[USER_ID_COL])

        # âœ… é€šè¿‡ ProblemDataset è·å–ç‰¹å¾
        #img_raw, txt_raw, txt_mask = self.problem_data.get_features(pid)
        knowledge = self.problem_data.get_knowledge(pid)

        return {
            'student_id': raw_stu_id,
            'problem_id': pid,
            'correct': torch.tensor(record[CORRECT_COL], dtype=torch.float),
            'knowledge': knowledge.clone(),
            
            # âœ… ä¼ é€’ç‰¹å¾åˆ—è¡¨
            #'img_raw': img_raw, 
            #'txt_raw': txt_raw,
            #'txt_mask': txt_mask
            
        }

    # ğŸ”¥ğŸ”¥ğŸ”¥ å…³é”®ï¼šå¤„ç†ç‰¹å¾åˆ—è¡¨çš„æ‰“åŒ… ğŸ”¥ğŸ”¥ğŸ”¥
    def collate_fn(self, batch):
        student_ids = torch.tensor([x['student_id'] for x in batch])
        problem_ids = torch.tensor([x['problem_id'] for x in batch])
        corrects = torch.stack([x['correct'] for x in batch]).float()
        knowledges = torch.stack([x['knowledge'] for x in batch])

        '''
        # 1. å›¾åƒç‰¹å¾: List[List[Tensor]] -> List[BatchTensor]
        # zip(*all_imgs) ä¼šæŠŠ layer1 èšåˆï¼Œlayer2 èšåˆ...
        all_imgs = [x['img_raw'] for x in batch]
        batch_img_raw = [torch.stack(layers) for layers in zip(*all_imgs)]
        
        # 2. æ–‡æœ¬ç‰¹å¾: List[List[Tensor]] -> List[BatchTensor]
        all_txts = [x['txt_raw'] for x in batch]
        batch_txt_raw = [torch.stack(layers) for layers in zip(*all_txts)]

        # 3. Mask: List[Tensor] -> BatchTensor
        batch_txt_mask = torch.stack([x['txt_mask'] for x in batch])
        '''
        return {
            'student_ids': student_ids,
            'problem_ids': problem_ids,
            'corrects': corrects,
            'knowledges': knowledges,
            
            #'img_raw': batch_img_raw, 
            #'txt_raw': batch_txt_raw,
            #'txt_mask': batch_txt_mask # [Batch, 80]
            
        }

    def create_dataloader(self, sampler, batch_size, num_workers):
        # è‡ªåŠ¨è°ƒæ•´å‚æ•°
        prefetch_factor = 2 if num_workers > 0 else None
        persistent_workers = True if num_workers > 0 else False
        
        return DataLoader(
            self,
            batch_size=batch_size,
            sampler=sampler,
            num_workers=num_workers,
            pin_memory=True, # GPUé©»ç•™çš„è¯å…¶å®è¿™ä¸ªä¹Ÿå¯ä»¥Falseï¼Œä¸è¿‡Trueä¹Ÿæ²¡äº‹
            collate_fn=self.collate_fn,
            persistent_workers=persistent_workers, # âœ… å¿…é¡»å’Œ num_workers>0 é…åˆ
            prefetch_factor=prefetch_factor # âœ… å¿…é¡»å’Œ num_workers>0 é…åˆ
        )
from collections import defaultdict
import random
import torch.distributed as dist
from torch.utils.data import Sampler

class DistributedBalancedProblemBatchSampler(Sampler):
    def __init__(self, dataset, batch_size, max_problems=200, num_replicas=None, rank=None, seed=42):
        self.dataset = dataset
        self.batch_size = batch_size
        self.max_problems = max_problems  # æ¯ä¸ª batch æœ€å¤š 200 ä¸ªé¢˜ç›®

        # åˆ†å¸ƒå¼è®¾ç½®
        if num_replicas is None:
            if not dist.is_initialized():
                num_replicas = 1
            else:
                num_replicas = dist.get_world_size()
        self.num_replicas = num_replicas

        if rank is None:
            if not dist.is_initialized():
                rank = 0
            else:
                rank = dist.get_rank()
        self.rank = rank

        self.seed = seed
        self.epoch = 0

        # æ„å»ºé¢˜ç›®åˆ°ç´¢å¼•çš„æ˜ å°„ï¼ˆå‡è®¾ dataset æœ‰ PROBLEM_ID_COL å­—æ®µï¼‰
        self.problem_to_indices = defaultdict(list)
        for idx in range(len(dataset)):
            pid = dataset.records.iloc[idx][PROBLEM_ID_COL]  # æ›¿æ¢ä¸ºä½ çš„é¢˜ç›® ID åˆ—å
            self.problem_to_indices[pid].append(idx)
        self.unique_problems = list(self.problem_to_indices.keys())

        # è®¡ç®—æ¯ä¸ª rank çš„ batch æ•°é‡
        self.num_samples = len(dataset) // self.num_replicas  # æ¯ GPU çš„æ ·æœ¬æ•°
        self.total_size = self.num_samples * self.num_replicas  # å…¨å±€æ ·æœ¬æ•°ï¼ˆå¯¹é½ï¼‰

    def set_epoch(self, epoch):
        self.epoch = epoch  # ç”¨äºåŒæ­¥ä¸åŒ epoch çš„éšæœºçŠ¶æ€

    def __iter__(self):
        # è®¾ç½®éšæœºç§å­ï¼ˆç¡®ä¿åˆ†å¸ƒå¼ç¯å¢ƒä¸‹å„è¿›ç¨‹åŒæ­¥ï¼‰
        g = random.Random()
        g.seed(self.seed + self.epoch)

        # è®¡ç®—æ¯ä¸ª rank çš„ batch æ•°é‡
        total_batches = (len(self.dataset) // self.batch_size) // self.num_replicas

        for _ in range(total_batches):
            # 1. éšæœºé€‰æ‹©æœ€å¤š 200 ä¸ªé¢˜ç›®
            selected_pids = g.sample(
                self.unique_problems,
                min(self.max_problems, len(self.unique_problems))
            )

            # 2. è®¡ç®—æ¯ä¸ªé¢˜ç›®åº”è¯¥è´¡çŒ®å¤šå°‘æ ·æœ¬ï¼ˆå°½é‡å‡åŒ€åˆ†å¸ƒï¼‰
            samples_per_problem = max(1, self.batch_size // len(selected_pids))

            # 3. ä»æ¯ä¸ªé¢˜ç›®ä¸­æŠ½å– samples_per_problem æ¡è®°å½•
            batch_indices = []
            for pid in selected_pids:
                indices = self.problem_to_indices[pid]
                batch_indices.extend(
                    g.choices(indices, k=samples_per_problem)
                )

            # 4. å¦‚æœæ ·æœ¬æ•°ä¸è¶³ batch_sizeï¼Œä»å·²é€‰é¢˜ç›®ä¸­éšæœºè¡¥é½
            if len(batch_indices) < self.batch_size:
                remaining = self.batch_size - len(batch_indices)
                batch_indices.extend(
                    g.choices(batch_indices, k=remaining)  # ä»æœ¬ batch å·²é€‰æ ·æœ¬ä¸­éšæœºé‡å¤
                )

            # 5. ç¡®ä¿ batch_size å¯¹é½ num_replicasï¼ˆåˆ†å¸ƒå¼è®­ç»ƒï¼‰
            while len(batch_indices) % self.num_replicas != 0:
                batch_indices.append(g.choice(batch_indices))  # éšæœºè¡¥ä¸€ä¸ª

            # 6. æŒ‰ rank åˆ†é…æ•°æ®ï¼ˆåˆ†å¸ƒå¼ï¼‰
            indices_per_rank = len(batch_indices) // self.num_replicas
            start = self.rank * indices_per_rank
            end = start + indices_per_rank

            yield batch_indices[start:end]

    def __len__(self):
        return (len(self.dataset) // self.batch_size) // self.num_replicas


# æ–°å¢å…¨å±€æ•°æ®é›†åŠ è½½
class FullDataset:
    def __init__(self):
        self.problem_data = ProblemDataset(OUTPUT_FILE)  # é¢˜ç›®æ•°æ®ï¼ˆåŒ…å«æ‰€æœ‰é¢˜ç›®ï¼‰
        self.train_records = RecordDataset(mode='train')
        self.val_records = RecordDataset(mode='val')
        self.test_records = RecordDataset(mode='test')
        
    def get_all_records(self):
        """æ•´åˆæ‰€æœ‰ç­”é¢˜è®°å½•"""
        return pd.concat([
            self.train_records.records,
            self.val_records.records,
            self.test_records.records
        ])


class RelationBuilder:
    def __init__(self, problem_dataset, full_dataset):
        self.problem_data = problem_dataset
        self.record_data = full_dataset.get_all_records()  # å…³é”®ä¿®æ”¹
        self.hetero_graph = HeteroData()


    def build_graph(self):
        self.hetero_graph.edge_types = [
            ('problem', 'has_knowledge', 'knowledge'),
            ('problem', 'related', 'problem'),
            ('knowledge', 'correlate', 'knowledge')
          
        ]
        self._build_problem_concept_edges()
        # æ·»åŠ èŠ‚ç‚¹ç‰¹å¾å’Œæ„å»ºè¾¹ï¼ˆåŸæœ‰é€»è¾‘ä¸å˜ï¼‰
        #self._add_problem_nodes(FUSION_FEATURES_PATH)
        
        return self.hetero_graph



    '''
    def _add_problem_nodes(self, feature_dir):
        """
        æœ€å°åŒ–æ£€æŸ¥ç‰ˆæœ¬ï¼šä»…åŠ è½½ç‰¹å¾å¹¶è®¡ç®—çŸ¥è¯†ç‚¹å‡å€¼ï¼Œè¾“å‡ºå…³é”®ç»´åº¦ä¿¡æ¯
        """
        # 1. ç¡®ä¿knowledgeèŠ‚ç‚¹æœ‰æ˜ç¡®çš„num_nodes
        num_knowledge = TOTAL_SKILLS
        self.hetero_graph['knowledge'].num_nodes = num_knowledge

        # 2. åŠ è½½é¢˜ç›®ç‰¹å¾
        pids = sorted(int(pid) for pid in self.problem_data.valid_pids)
        feats = [torch.load(os.path.join(feature_dir, f"{pid}.pt")).detach().numpy() for pid in pids]

        problem_feats = torch.from_numpy(np.array(feats)).float()
        self.hetero_graph['problem'].x = problem_feats
        print(f"å·²åŠ è½½ {len(pids)} ä¸ªé¢˜ç›®ç‰¹å¾ | ç»´åº¦: {problem_feats.shape}")

        # 3. è®¡ç®—çŸ¥è¯†ç‚¹å¹³å‡ç‰¹å¾
        edge_index = self.hetero_graph['problem', 'has_knowledge', 'knowledge'].edge_index
        
        # è®¡ç®—å‡å€¼
        knowledge_feats = torch.zeros(
            (num_knowledge, problem_feats.size(1)),
            device=problem_feats.device
        )
        knowledge_feats.scatter_add_(
            0,
            edge_index[1].unsqueeze(-1).expand(-1, problem_feats.size(1)),
            problem_feats[edge_index[0]]
        )
        
        # ä¿®æ­£ç‚¹ï¼šç»Ÿä¸€æ•°æ®ç±»å‹
        degree = torch.zeros(num_knowledge, 
                        device=edge_index.device,
                        dtype=torch.float32)  # æ˜ç¡®ä½¿ç”¨float32
        degree.scatter_add_(0, 
                        edge_index[1], 
                        torch.ones_like(edge_index[1], dtype=torch.float32))  # ç¡®ä¿ç±»å‹åŒ¹é…
        
        self.hetero_graph['knowledge'].x = knowledge_feats / degree.unsqueeze(-1)
        print(f"å·²è®¡ç®— {num_knowledge} ä¸ªçŸ¥è¯†ç‚¹ç‰¹å¾ | ç»´åº¦: {knowledge_feats.shape}")
    '''
    def _add_problem_nodes(self, feature_dir):
        """
        æœ€ç»ˆä¿®æ”¹ç‰ˆæœ¬ï¼šé¿å…ä½¿ç”¨register_buffer
        """
        
        feature_dir = TEXT_FEATURES_DIR
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ç¡®ä¿knowledgeèŠ‚ç‚¹å®šä¹‰
        num_knowledge = TOTAL_SKILLS
        self.hetero_graph['knowledge'].num_nodes = num_knowledge

        # åˆå§‹åŒ–éšæœºæŠ•å½±çŸ©é˜µï¼ˆè®¾å¤‡æ„ŸçŸ¥ï¼‰
        if not hasattr(self, 'random_projection'):
            input_dim = 256 * 768
            output_dim = 512
            # ç›´æ¥ä¿å­˜å¼ é‡ï¼ˆæ— éœ€register_bufferï¼‰
            self.random_projection = torch.randn(input_dim, output_dim, device=device) * (2.0 / input_dim)**0.5
            
        # åŠ è½½é¢˜ç›®ç‰¹å¾ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        pids = sorted(int(pid) for pid in self.problem_data.valid_pids)
        
        # å‡è®¾æ¯ä¸ª `feat` åŸå§‹æ˜¯ [256, 768]
        with torch.no_grad():
            all_feats = []
            for pid in pids:
                feat = torch.load(os.path.join(feature_dir, f"{pid}.pt")).to(device)  # åŸå§‹ [256, 768]


                # çº¿æ€§å˜æ¢ï¼šç›´æ¥å°† [256, 768] è½¬æ¢ä¸º [256, 1024]
                
                linear_transform = torch.nn.Linear(768, 512).to(device)  # æ³¨æ„è¿™é‡Œçš„è¾“å…¥æ˜¯ 768ï¼Œè¾“å‡ºæ˜¯ 1024
                feat = linear_transform(feat)  # ç»è¿‡çº¿æ€§å˜æ¢ï¼Œå˜æˆ [256, 1024]
                
                # å¹³å‡æ± åŒ–åˆ°æœ€ç»ˆçš„ [1024]
                feat = feat.mean(dim=0)  # [1024]

                all_feats.append(feat)

            problem_feats = torch.stack(all_feats).to(device)  # [num_problems, 1024]



        # è½¬æ¢ç»´åº¦ï¼ˆæ˜¾å¼ç¡®ä¿è®¾å¤‡ä¸€è‡´ï¼‰
        #with torch.no_grad():
        #    orig_feats = torch.stack(all_feats).to(device)  # æ˜¾å¼æŒ‡å®šè®¾å¤‡
        #    flattened = orig_feats.view(-1, 256*768)
            # ç¡®ä¿æŠ•å½±çŸ©é˜µåœ¨ç›¸åŒè®¾å¤‡
       #     problem_feats = torch.matmul(flattened, self.random_projection.to(device))
       
        
        self.hetero_graph['problem'].x = problem_feats
        print(f"å·²åŠ è½½ {len(pids)} ä¸ªé¢˜ç›®ç‰¹å¾ | è½¬æ¢åç»´åº¦: {problem_feats.shape}")
        


        num_knowledge = TOTAL_SKILLS
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        # åŠ è½½çŸ¥è¯†ç‚¹ç‰¹å¾ï¼ˆç›´æ¥æŒ‰IDé¡ºåºï¼‰
        knowledge_features = torch.load(os.path.join(KNOW_PT))  # ä½ çš„ OUTPUT_PATH
        feature_matrix = torch.stack([knowledge_features[i] for i in range(num_knowledge)]).to(device)

        # æ›¿æ¢åŸæœ‰çš„ scatter_add è®¡ç®—ï¼ˆå¦‚æœä¸éœ€è¦èšåˆé¢˜ç›®ç‰¹å¾ï¼‰
        self.hetero_graph['knowledge'].x = feature_matrix
        print(f"ç›´æ¥åŠ è½½ {num_knowledge} ä¸ªçŸ¥è¯†ç‚¹ç‰¹å¾ | ç»´åº¦: {feature_matrix.shape}")
        
        
    '''
    def _add_problem_nodes(self, feature_dir):
        """
        æœ€ç»ˆä¿®æ”¹ç‰ˆæœ¬ï¼šé¿å…ä½¿ç”¨register_buffer
        """
        feature_dir = TEXT_FEATURES_DIR
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ç¡®ä¿knowledgeèŠ‚ç‚¹å®šä¹‰
        num_knowledge = TOTAL_SKILLS
        self.hetero_graph['knowledge'].num_nodes = num_knowledge

        # åˆå§‹åŒ–éšæœºæŠ•å½±çŸ©é˜µï¼ˆè®¾å¤‡æ„ŸçŸ¥ï¼‰
        if not hasattr(self, 'random_projection'):
            input_dim = 256 * 768
            output_dim = 512
            # ç›´æ¥ä¿å­˜å¼ é‡ï¼ˆæ— éœ€register_bufferï¼‰
            self.random_projection = torch.randn(input_dim, output_dim, device=device) * (2.0 / input_dim)**0.5
            
        # åŠ è½½é¢˜ç›®ç‰¹å¾ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        pids = sorted(int(pid) for pid in self.problem_data.valid_pids)
        
        # å‡è®¾æ¯ä¸ª `feat` åŸå§‹æ˜¯ [256, 768]
        with torch.no_grad():
            all_feats = []
            for pid in pids:
                feat = torch.load(os.path.join(feature_dir, f"{pid}.pt")).to(device)  # åŸå§‹ [256, 768]


                # çº¿æ€§å˜æ¢ï¼šç›´æ¥å°† [256, 768] è½¬æ¢ä¸º [256, 1024]
                linear_transform = torch.nn.Linear(768, 512).to(device)  # æ³¨æ„è¿™é‡Œçš„è¾“å…¥æ˜¯ 768ï¼Œè¾“å‡ºæ˜¯ 1024
                feat = linear_transform(feat)  # ç»è¿‡çº¿æ€§å˜æ¢ï¼Œå˜æˆ [256, 1024]

                # å¹³å‡æ± åŒ–åˆ°æœ€ç»ˆçš„ [1024]
                feat = feat.mean(dim=0)  # [1024]

                all_feats.append(feat)

            problem_feats = torch.stack(all_feats).to(device)  # [num_problems, 1024]



        # è½¬æ¢ç»´åº¦ï¼ˆæ˜¾å¼ç¡®ä¿è®¾å¤‡ä¸€è‡´ï¼‰
        #with torch.no_grad():
        #    orig_feats = torch.stack(all_feats).to(device)  # æ˜¾å¼æŒ‡å®šè®¾å¤‡
        #    flattened = orig_feats.view(-1, 256*768)
            # ç¡®ä¿æŠ•å½±çŸ©é˜µåœ¨ç›¸åŒè®¾å¤‡
       #     problem_feats = torch.matmul(flattened, self.random_projection.to(device))
       
        
        self.hetero_graph['problem'].x = problem_feats
        print(f"å·²åŠ è½½ {len(pids)} ä¸ªé¢˜ç›®ç‰¹å¾ | è½¬æ¢åç»´åº¦: {problem_feats.shape}")

        # çŸ¥è¯†ç‚¹ç‰¹å¾è®¡ç®—ï¼ˆä¿æŒåŸé€»è¾‘ä¸å˜ï¼‰
        edge_index = self.hetero_graph['problem', 'has_knowledge', 'knowledge'].edge_index.to(device)
        
        knowledge_feats = torch.zeros(
            (num_knowledge, 512),
            device=device
        )
        knowledge_feats.scatter_add_(
            0,
            edge_index[1].unsqueeze(-1).expand(-1, 512),
            problem_feats[edge_index[0]]
        )
        
        degree = torch.zeros(num_knowledge, device=device)
        degree.scatter_add_(
            0,
            edge_index[1],
            torch.ones(edge_index.size(1), device=device)
        )
        degree = degree.clamp(min=1)
        
        self.hetero_graph['knowledge'].x = (knowledge_feats / degree.unsqueeze(-1)).to(device)
        print(f"å·²è®¡ç®— {num_knowledge} ä¸ªçŸ¥è¯†ç‚¹ç‰¹å¾ | ç»´åº¦: {knowledge_feats.shape}")
    '''
    '''
    def _add_problem_nodes(self, feature_dir):
        """
        æœ€ç»ˆä¿®æ”¹ç‰ˆæœ¬ï¼šä»…åŠ è½½é¢˜ç›®åŸå§‹ç‰¹å¾ [256, 768]ï¼Œä¸åšæ˜ å°„
        """
        feature_dir = TEXT_FEATURES_DIR
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')

        num_knowledge = TOTAL_SKILLS
        self.hetero_graph['knowledge'].num_nodes = num_knowledge

        # åŠ è½½åŸå§‹é¢˜ç›®ç‰¹å¾ [256, 768]
        pids = sorted(int(pid) for pid in self.problem_data.valid_pids)
        all_feats = []

        with torch.no_grad():
            for pid in pids:
                feat = torch.load(os.path.join(feature_dir, f"{pid}.pt")).to(device)  # [256, 768]
                all_feats.append(feat)

        # ç›´æ¥ä¿å­˜åŸå§‹ç‰¹å¾ï¼ˆä¸flattenã€ä¸å˜æ¢ï¼‰
        problem_feats = torch.stack(all_feats)  # [num_problems, 256, 768]
        self.hetero_graph['problem'].x = problem_feats
        print(f"å·²åŠ è½½ {len(pids)} ä¸ªé¢˜ç›®åŸå§‹ç‰¹å¾ | ç»´åº¦: {problem_feats.shape}")

        # è®¡ç®—çŸ¥è¯†ç‚¹ç‰¹å¾ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        edge_index = self.hetero_graph['problem', 'has_knowledge', 'knowledge'].edge_index.to(device)

        # å¹³å‡æ± åŒ–é¢˜ç›®ç‰¹å¾ç”¨äºçŸ¥è¯†ç‚¹
        pooled_feats = problem_feats.mean(dim=1)  # [num_problems, 768]

        knowledge_feats = torch.zeros((num_knowledge, 768), device=device)
        knowledge_feats.scatter_add_(
            0,
            edge_index[1].unsqueeze(-1).expand(-1, 768),
            pooled_feats[edge_index[0]]
        )

        degree = torch.zeros(num_knowledge, device=device)
        degree.scatter_add_(0, edge_index[1], torch.ones(edge_index.size(1), device=device))
        degree = degree.clamp(min=1)

        self.hetero_graph['knowledge'].x = (knowledge_feats / degree.unsqueeze(-1)).to(device)
        print(f"å·²è®¡ç®— {num_knowledge} ä¸ªçŸ¥è¯†ç‚¹ç‰¹å¾ | ç»´åº¦: {knowledge_feats.shape}")

    '''
    '''
    def _add_problem_nodes(self, feature_dir):
        """
        æœ€ç»ˆä¿®æ”¹ç‰ˆæœ¬ï¼šé¿å…ä½¿ç”¨register_buffer
        """
        feature_dir = IMAGE_FEATURES_DIR
        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
        
        # ç¡®ä¿knowledgeèŠ‚ç‚¹å®šä¹‰
        num_knowledge = TOTAL_SKILLS
        self.hetero_graph['knowledge'].num_nodes = num_knowledge

      
            
        # åŠ è½½é¢˜ç›®ç‰¹å¾ï¼ˆä¿æŒåŸé€»è¾‘ï¼‰
        pids = sorted(int(pid) for pid in self.problem_data.valid_pids)
        
        # å‡è®¾æ¯ä¸ª feat åŸå§‹æ˜¯ [512, 56, 56]
        with torch.no_grad():
            all_feats = []
            for pid in pids:
                feat = torch.load(os.path.join(feature_dir, f"{pid}.pt")).to(device)  # åŸå§‹ [512, 56, 56]

                # å‡è®¾æ˜¯å·ç§¯è¾“å…¥ï¼Œæˆ‘ä»¬å¯ä»¥é€šè¿‡ä¸€ä¸ªå·ç§¯å±‚å°† [512, 56, 56] è½¬æ¢ä¸º [1024]
                # è¿™é‡Œå…ˆç”¨å·ç§¯å±‚æ¥å¤„ç†
                conv_layer = nn.Conv2d(in_channels=512, out_channels=1024, kernel_size=1).to(device)  # [512, 56, 56] -> [1024, 56, 56]
                feat = conv_layer(feat)  # ç»è¿‡å·ç§¯ï¼Œå˜æˆ [1024, 56, 56]

                # è¿›è¡Œæ± åŒ–æ“ä½œï¼Œå°† [1024, 56, 56] æ± åŒ–ä¸º [1024, 1, 1]
                feat = nn.AdaptiveAvgPool2d(1)(feat)  # ä½¿ç”¨è‡ªé€‚åº”æ± åŒ–ï¼Œè¾“å‡º [1024, 1, 1]

                # å±•å¹³ï¼ˆflattenï¼‰ä¸º [1024]
                feat = feat.view(-1)  # å°† [1024, 1, 1] å±•å¹³ä¸º [1024]

                all_feats.append(feat)

            problem_feats = torch.stack(all_feats).to(device)  # [num_problems, 1024]



        # è½¬æ¢ç»´åº¦ï¼ˆæ˜¾å¼ç¡®ä¿è®¾å¤‡ä¸€è‡´ï¼‰
        #with torch.no_grad():
        #    orig_feats = torch.stack(all_feats).to(device)  # æ˜¾å¼æŒ‡å®šè®¾å¤‡
        #    flattened = orig_feats.view(-1, 256*768)
            # ç¡®ä¿æŠ•å½±çŸ©é˜µåœ¨ç›¸åŒè®¾å¤‡
       #     problem_feats = torch.matmul(flattened, self.random_projection.to(device))
       
        
        self.hetero_graph['problem'].x = problem_feats
        print(f"å·²åŠ è½½ {len(pids)} ä¸ªé¢˜ç›®ç‰¹å¾ | è½¬æ¢åç»´åº¦: {problem_feats.shape}")

        # çŸ¥è¯†ç‚¹ç‰¹å¾è®¡ç®—ï¼ˆä¿æŒåŸé€»è¾‘ä¸å˜ï¼‰
        edge_index = self.hetero_graph['problem', 'has_knowledge', 'knowledge'].edge_index.to(device)
        
        knowledge_feats = torch.zeros(
            (num_knowledge, 1024),
            device=device
        )
        knowledge_feats.scatter_add_(
            0,
            edge_index[1].unsqueeze(-1).expand(-1, 1024),
            problem_feats[edge_index[0]]
        )
        
        degree = torch.zeros(num_knowledge, device=device)
        degree.scatter_add_(
            0,
            edge_index[1],
            torch.ones(edge_index.size(1), device=device)
        )
        degree = degree.clamp(min=1)
        
        self.hetero_graph['knowledge'].x = (knowledge_feats / degree.unsqueeze(-1)).to(device)
        print(f"å·²è®¡ç®— {num_knowledge} ä¸ªçŸ¥è¯†ç‚¹ç‰¹å¾ | ç»´åº¦: {knowledge_feats.shape}")
    '''
    def _build_problem_concept_edges(self):
        """æ„å»ºé¢˜ç›®-çŸ¥è¯†ç‚¹è¾¹ï¼ˆä¿®æ­£ç‰ˆæœ¬ï¼‰"""
        edge_index = []
        for pid in self.problem_data.valid_pids:
            k_vector = self.problem_data.knowledge_dict[int(pid)]
            
            # ä¿®æ­£ç´¢å¼•æå–é€»è¾‘
            indices = torch.where(k_vector == 1)[0]  # æå–æ»¡è¶³æ¡ä»¶çš„ç´¢å¼•å¼ é‡
            knowledge_ids = indices.tolist()         # è½¬æ¢ä¸ºåˆ—è¡¨
            
            for k_id in knowledge_ids:
                edge_index.append([int(pid), k_id])
        
        
        edge_index_tensor = torch.tensor(edge_index).t().contiguous()
        self.hetero_graph['problem', 'has_knowledge', 'knowledge'].edge_index = edge_index_tensor
        self.hetero_graph['problem', 'has_knowledge', 'knowledge'].edge_attr = torch.ones(edge_index_tensor.size(1))    
        edge_index = self.hetero_graph['problem', 'has_knowledge', 'knowledge'].edge_index
        print("ç›®æ ‡èŠ‚ç‚¹ç´¢å¼•æœ€å¤§å€¼:", edge_index[1].max().item())  # åº”è¾“å‡º82
   