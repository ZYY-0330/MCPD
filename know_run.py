import torch
import torch.nn as nn
from transformers import BertModel, BertTokenizer
import json
import os
from tqdm import tqdm

from configs.dataset_config import *

class KnowledgeExtractor:
    def __init__(self, model_path, device):
        self.device = device
        print(f"ğŸš€ Loading BERT from {model_path}...")
        self.tokenizer = BertTokenizer.from_pretrained(model_path)
        self.model = BertModel.from_pretrained(model_path).to(device)
        self.model.eval()

    def extract(self, text_list):
        """
        è¾“å…¥: æ–‡æœ¬åˆ—è¡¨ ["Maths", "Number", ...]
        è¾“å‡º: Tensor [Batch, 768]
        """
        # 1. Tokenize
        encoded = self.tokenizer(
            text_list,
            padding=True,
            truncation=True,
            max_length=32, 
            return_tensors='pt'
        )
        
        input_ids = encoded['input_ids'].to(self.device)
        attention_mask = encoded['attention_mask'].to(self.device)

        # 2. Forward
        with torch.no_grad():
            outputs = self.model(input_ids=input_ids, attention_mask=attention_mask)
            
            # æ–¹æ¡ˆ A: å– [CLS] token (æ¨è)
            cls_embeddings = outputs.last_hidden_state[:, 0, :]
            
            return cls_embeddings.cpu()

def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"âœ… Using device: {device}")

    # ==========================================
    # 1. è¯»å– JSON æ•°æ®å¹¶æ­£ç¡®æ’åº
    # ==========================================
    print(f"ğŸ“‚ æ­£åœ¨è¯»å–çŸ¥è¯†ç‚¹æ–‡ä»¶: {KNOWLEDGE_JSON}...")
    
    if not KNOWLEDGE_JSON.exists():
        raise FileNotFoundError(f"âŒ æ‰¾ä¸åˆ°æ–‡ä»¶: {KNOWLEDGE_JSON}")

    with open(KNOWLEDGE_JSON, 'r', encoding='utf-8') as f:
        know_map = json.load(f)
    
    # ğŸš¨ å…³é”®æ­¥éª¤ï¼šæŒ‰ç…§ ID çš„æ•´æ•°å€¼æ’åº
    # JSON çš„ key æ˜¯å­—ç¬¦ä¸² ("0", "1", "10")ã€‚
    # å¦‚æœç›´æ¥ sortï¼Œ"10" ä¼šæ’åœ¨ "2" å‰é¢ã€‚
    # æ‰€ä»¥å¿…é¡»ç”¨ key=lambda x: int(x)
    sorted_ids = sorted(know_map.keys(), key=lambda x: int(x))
    
    print(f"ğŸ“Š æ£€æµ‹åˆ° {len(sorted_ids)} ä¸ªçŸ¥è¯†ç‚¹")
    
    # æ£€æŸ¥ ID æ˜¯å¦è¿ç»­ (å¯é€‰ï¼Œé˜²æ­¢ä¸­é—´ç¼º ID å¯¼è‡´è¡Œå·é”™ä½)
    max_id = int(sorted_ids[-1])
    if max_id + 1 != len(sorted_ids):
        print(f"âš ï¸ è­¦å‘Š: ID å¯èƒ½ä¸è¿ç»­ï¼æœ€å¤§IDæ˜¯ {max_id}, ä½†æ€»æ•°åªæœ‰ {len(sorted_ids)}")
        # å¦‚æœä½ çš„æ¨¡å‹ä¾èµ– embedding(id)ï¼Œè¿™é€šå¸¸æ„å‘³ç€ä½ éœ€è¦å¡«è¡¥ç©ºç¼ºæˆ–é‡æ–°æ˜ å°„
    
    # ç”Ÿæˆå¯¹åº”çš„æ–‡æœ¬åˆ—è¡¨
    # texts[0] å°±æ˜¯ ID=0 çš„æ–‡æœ¬
    # texts[1] å°±æ˜¯ ID=1 çš„æ–‡æœ¬
    texts = [know_map[pid] for pid in sorted_ids]
    
    print(f"ğŸ“ æ ·ä¾‹æ£€æŸ¥:")
    print(f"   Row 0 (ID={sorted_ids[0]}): {texts[0]}")
    print(f"   Row 1 (ID={sorted_ids[1]}): {texts[1]}")
    # print(f"   Row 10 (ID={sorted_ids[10]}): {texts[10]}") # å¦‚æœæœ‰10çš„è¯

    # ==========================================
    # 2. æå–ç‰¹å¾
    # ==========================================
    extractor = KnowledgeExtractor(MODEL_PATH, device)

    print("ğŸš€ å¼€å§‹æå– BERT ç‰¹å¾...")
    # å› ä¸ºçŸ¥è¯†ç‚¹æ•°é‡é€šå¸¸ä¸å¤š(å‡ åå‡ ç™¾ä¸ª)ï¼Œä¸€æ¬¡æ€§æå–æœ€å¿«
    emb_matrix = extractor.extract(texts)
    
    # Check ç»´åº¦
    print(f"ğŸ‘€ æå–ç»“æœå½¢çŠ¶: {emb_matrix.shape}") 
    # åº”è¯¥æ˜¯ [Total_Knowledge_Count, 768]

    # ==========================================
    # 3. ä¿å­˜
    # ==========================================
    print(f"ğŸ’¾ ä¿å­˜åˆ° {KNOW_OUTPUT_FILE}...")
    torch.save(emb_matrix, KNOW_OUTPUT_FILE)
    print("âœ… å®Œæˆï¼")
    print(f"   ç°åœ¨ä½ å¯ä»¥åœ¨æ¨¡å‹ä¸­ä½¿ç”¨ nn.Embedding.from_pretrained(torch.load('{KNOW_OUTPUT_FILE}'))")

if __name__ == "__main__":
    main()