import torch
import torch.nn as nn
from torch.utils.data import DataLoader, Dataset
from torchvision import models, transforms
from transformers import BertModel, BertTokenizer
from tqdm import tqdm
import os
import json
import pandas as pd
from PIL import Image
import torch.nn.functional as F                  # <--- ç”¨äºŽ max_pool2d, interpolate
import torchvision.transforms.functional as TF   # <--- ç”¨äºŽ SquarePad é‡Œçš„ pad
# å¼•å…¥ä½ çš„é…ç½® (ç¡®ä¿è·¯å¾„éƒ½åœ¨è¿™é‡Œé¢å®šä¹‰å¥½)
from configs.dataset_config import *
# 1. å®šä¹‰å¡«å……ç±» (å¿…é¡»æ”¾åœ¨ RawDataDataset å¤–é¢æˆ–å‰é¢)
import torchvision.transforms.functional as TF  # <--- 1. æ”¹åå¼•ç”¨ï¼

class SquarePad:
    def __call__(self, image):
        # ç¡®ä¿ image æ˜¯ PIL Image
        w, h = image.size
        max_wh = max(w, h)
        p_left = (max_wh - w) // 2
        p_top = (max_wh - h) // 2
        padding = (p_left, p_top, max_wh - w - p_left, max_wh - h - p_top)
        
        # 2. ä½¿ç”¨ TF.pad è€Œä¸æ˜¯ F.pad
        return TF.pad(image, padding, 0, 'constant')

# 2. ä¿®æ”¹åŽçš„ Dataset ç±»
class RawDataDataset(Dataset):
    def __init__(self, img_dir, text_dir, tokenizer, max_len=80):
        self.img_dir = img_dir 
        self.tokenizer = tokenizer
        self.max_len = max_len
        
        print(f"    Loading text from {text_dir}...")
        with open(text_dir, 'r', encoding='utf-8') as f:
            self.text_data = json.load(f)
        self.pids = list(self.text_data.keys())
        
        # âœ…âœ…âœ… ä¿®æ­£åŽçš„ Transform âœ…âœ…âœ…
        # 1. SquarePad: ä¿æŒæ¯”ä¾‹ï¼Œå¡«å……é»‘è¾¹ (è§£å†³é•¿å›¾å˜å½¢é—®é¢˜)
        # 2. Resize: ç¼©æ”¾åˆ° 224x224
        # 3. ToTensor & Normalize: æ ‡å‡†åŒ–
        self.img_transform = transforms.Compose([
            SquarePad(),                   # <--- æ ¸å¿ƒä¿®æ”¹ï¼
            transforms.Resize((224, 224)), 
            transforms.ToTensor(),
            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])
        ])

    def __len__(self):
        return len(self.pids)

    def __getitem__(self, idx):
        pid = self.pids[idx]
        base_dir = str(self.img_dir)
        img_path_jpg = os.path.join(base_dir, f"{pid}.jpg")
        img_path_png = os.path.join(base_dir, f"{pid}.png")
        
        img = None
        if os.path.exists(img_path_png):
            img = Image.open(img_path_png).convert('RGB')
        elif os.path.exists(img_path_jpg):
            img = Image.open(img_path_jpg).convert('RGB')
        
        if img is None:
            img = Image.new('RGB', (224, 224), (0, 0, 0))
            
        # è¿™é‡Œä¼šè°ƒç”¨ä¸Šé¢å®šä¹‰å¥½çš„å« SquarePad çš„ transform
        img_tensor = self.img_transform(img)

       
     
        
        # --- B. å¤„ç†æ–‡æœ¬ ---
        # æ ¹æ®ä½ çš„jsonç»“æž„è°ƒæ•´ï¼Œå‡è®¾ key æ˜¯ 'content'
        if isinstance(self.text_data[pid], dict):
            content = self.text_data[pid].get('content', "")
        else:
            content = str(self.text_data[pid])

        encoding = self.tokenizer(
            content,
            max_length=self.max_len,
            padding='max_length',
            truncation=True,
            return_tensors='pt'
        )
        
        return {
            'pid': int(pid),
            'image': img_tensor,
            'input_ids': encoding['input_ids'].squeeze(0),
            'attention_mask': encoding['attention_mask'].squeeze(0)
        }

# ============================================================================
# 2. ç¦»çº¿æ¨¡åž‹å®šä¹‰ (å†»ç»“ç‰ˆ)
# ============================================================================
class OfflineResNet(nn.Module):
    def __init__(self):
        super().__init__()
        print("    Loading ResNet50...")
        resnet = models.resnet50(pretrained=True)
        self.layer0 = nn.Sequential(resnet.conv1, resnet.bn1, resnet.relu, resnet.maxpool)
        self.layer1 = resnet.layer1
        self.layer2 = resnet.layer2
        self.layer3 = resnet.layer3
        self.layer4 = resnet.layer4
        for param in self.parameters(): param.requires_grad = False
            
    def forward(self, x):
        x = self.layer0(x)
        l1 = self.layer1(x) 
        l2 = self.layer2(l1)
        l3 = self.layer3(l2)
        l4 = self.layer4(l3)
        return [l1, l2, l3, l4]

class OfflineBERT(nn.Module):
    def __init__(self, model_path):
        super().__init__()
        print(f"    Loading BERT from {model_path}...")
        self.bert = BertModel.from_pretrained(model_path)
        for param in self.parameters(): param.requires_grad = False
            
    def forward(self, input_ids, attention_mask):
        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask, output_hidden_states=True)
        return outputs.hidden_states

# ============================================================================
# 3. ä¸»æ‰§è¡Œå‡½æ•°
# ============================================================================
def main():
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"âœ… Using device: {device}")
    
    # è¾“å‡ºæ–‡ä»¶è·¯å¾„ (ä»Žconfigè¯»å–)
    # ç¡®ä¿ OUTPUT_FILE åœ¨ dataset_config.py é‡Œå®šä¹‰äº†ï¼Œæˆ–è€…åœ¨è¿™é‡Œç›´æŽ¥å†™æ­»è·¯å¾„
    # OUTPUT_FILE = "offline_features.pt" 
    
    # 1. å‡†å¤‡æ¨¡åž‹
    print("ðŸš€ æ­£åœ¨åŠ è½½æ¨¡åž‹...")
    try:
        img_model = OfflineResNet().to(device).eval()
        txt_model = OfflineBERT(MODEL_PATH).to(device).eval()
        tokenizer = BertTokenizer.from_pretrained(MODEL_PATH)
    except Exception as e:
        print(f"âŒ æ¨¡åž‹åŠ è½½å¤±è´¥: {e}")
        return

    # 2. å‡†å¤‡æ•°æ®
    print("ðŸ“‚ æ­£åœ¨è¯»å–æ•°æ®æ–‡ä»¶...")
    # ä½¿ç”¨æœ¬æ–‡ä»¶å®šä¹‰çš„ RawDataDataset
    dataset = RawDataDataset(IMAGE_DIR, TEXT_DIR, tokenizer)
    
    total_items = len(dataset)
    print(f"ðŸ“Š æ•°æ®é›†ç»Ÿè®¡: å…±å‘çŽ° {total_items} é“é¢˜ç›®")
    
    batch_size = 32
    loader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=4)
    total_batches = len(loader)

    # 3. å¼€å§‹æå–
    print(f"ðŸš€ å¼€å§‹ç‰¹å¾æå– (Batch Size: {batch_size}, Total Batches: {total_batches})...")
    cached_data = {} 

    with torch.no_grad():
        pbar = tqdm(loader, total=total_batches, unit="batch", desc="Processing")
        
        for batch in pbar:
            pids = batch['pid'].tolist()
            imgs = batch['image'].to(device)
            input_ids = batch['input_ids'].to(device)
            masks = batch['attention_mask'].to(device) # [B, 80]

            # è·‘æ¨¡åž‹
            img_feats = img_model(imgs) # list of 4 tensors
            txt_outputs = txt_model(input_ids, masks) 

            # å–å‡ºéœ€è¦çš„å±‚ (3, 8, 12)
            t_low = txt_outputs[3]
            t_mid = txt_outputs[8]
            t_high = txt_outputs[12]

           
                
                # --- æ‹†åˆ† Batch å¹¶è½¬å­˜ CPU ---
            for i, pid in enumerate(pids):
                # 1. å–å‡ºåŽŸå§‹ç‰¹å¾ (CPU)
                raw_l1 = img_feats[0][i].cpu() # 56x56
                raw_l2 = img_feats[1][i].cpu() # 28x28
                raw_l3 = img_feats[2][i].cpu() # 14x14
                raw_l4 = img_feats[3][i].cpu() # 7x7

                # =========================================================
                # ðŸš€ æ ¸å¿ƒä¼˜åŒ–ï¼šå½¢æ€å­¦è†¨èƒ€ + è‡ªé€‚åº”æœ€å¤§æ± åŒ–
                # =========================================================
                
                # A. å®šä¹‰è†¨èƒ€æ“ä½œ (Dilation)
                # åŽŸç†ï¼šç”¨ 3x3 çš„æœ€å¤§å€¼æ»¤æ³¢ (stride=1, padding=1) æ‰«ä¸€é
                # æ•ˆæžœï¼šæŠŠ 1px çš„ç»†çº¿ "åŠ ç²—" åˆ° 3pxï¼Œé˜²æ­¢ä¸‹é‡‡æ ·æ—¶ä¸¢å¤±
                # æ³¨æ„ï¼šraw_l1 æ˜¯ [C, H, W]ï¼Œéœ€è¦ unsqueeze(0) å˜æˆ [1, C, H, W] æ‰èƒ½åš MaxPool
                
                l1_dilated = F.max_pool2d(raw_l1.unsqueeze(0), kernel_size=3, stride=1, padding=1)
                l2_dilated = F.max_pool2d(raw_l2.unsqueeze(0), kernel_size=3, stride=1, padding=1)
                
                # B. æ‰§è¡Œæœ€å¤§æ± åŒ–ä¸‹é‡‡æ · (Downsampling)
                # ä½¿ç”¨ adaptive_max_pool2d å¼ºè½¬ 14x14
                # ç›¸æ¯” AvgPoolï¼Œå®ƒåªä¿ç•™"æœ‰ç‰¹å¾"çš„åƒç´ ï¼Œä¸ç¨€é‡Šä¿¡å·
                l1_14 = F.adaptive_max_pool2d(l1_dilated, (14, 14)).squeeze(0)
                l2_14 = F.adaptive_max_pool2d(l2_dilated, (14, 14)).squeeze(0)
                
                # =========================================================

                # 2. Layer 3 (14x14) ä¸éœ€è¦åŠ¨ï¼Œç›´æŽ¥ Clone
                l3_14 = raw_l3.clone()
                
                # 3. Layer 4 (7x7) å¤ªå°ï¼Œéœ€è¦ä¸Šé‡‡æ · (æ’å€¼)
                # ä¸Šé‡‡æ ·åªèƒ½ç”¨æ’å€¼ (interpolate)ï¼Œè¿™é‡Œç”¨åŒçº¿æ€§å³å¯
                l4_14 = F.interpolate(raw_l4.unsqueeze(0), size=(14, 14), mode='bilinear', align_corners=True).squeeze(0)

                # 4. æ‰“åŒ…å›¾åƒç‰¹å¾
                i_data = [l1_14, l2_14, l3_14, l4_14]

                
                # æ–‡æœ¬ç‰¹å¾ (Low, Mid, High)
                t_data = [
                    t_low[i].cpu().clone(),
                    t_mid[i].cpu().clone(),
                    t_high[i].cpu().clone()
                ]
                
                # âœ… [å…³é”®] ä¿å­˜ Mask!
                # å°† mask è½¬å›ž CPU ä¿å­˜
                m_data = masks[i].cpu().clone()

                # å­˜å…¥å­—å…¸
                cached_data[pid] = {
                    "img": i_data,
                    "txt": t_data,
                    "mask": m_data  # <--- Maskåœ¨è¿™é‡Œ
                }
            
            pbar.set_description(f"Processing (Extracted: {len(cached_data)}/{total_items})")

    # 4. ä¿å­˜
    print(f"\nðŸ’¾ æ­£åœ¨ä¿å­˜åˆ° {OUTPUT_FILE} (è¿™å¯èƒ½éœ€è¦å‡ ç§’é’Ÿ)...")
    torch.save(cached_data, OUTPUT_FILE)
    
    file_size_mb = os.path.getsize(OUTPUT_FILE) / 1024 / 1024
    print(f"âœ… å®Œæˆï¼æ–‡ä»¶å¤§å°: {file_size_mb:.2f} MB")
    print(f"âœ… æˆåŠŸæå–äº† {len(cached_data)} é“é¢˜ç›®çš„ç‰¹å¾ã€‚")

if __name__ == "__main__":
    main()